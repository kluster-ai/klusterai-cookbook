{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "76f1454d",
      "metadata": {},
      "source": [
        "# Combat Hallucinations with **Verify Reliability**\n",
        "\n",
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/kluster-ai/klusterai-cookbook/blob/main/examples/combat-hallucinations.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "581c9428",
      "metadata": {},
      "source": [
        "Large language models occasionally invent facts (‚Äúhallucinations‚Äù). **[Verify Reliability](https://docs.kluster.ai/get-started/verify/reliability/overview/)** is a drop‚Äëin fact‚Äëchecker that scores any LLM response for reliability, either with one click inside the [kluster Playground](https://platform.kluster.ai/playground) or via a simple API call.\n",
        "\n",
        "This notebook shows you how to:\n",
        "1. Call the `POST /v1/verify/reliability` endpoint to fact‚Äëcheck model output programmatically.\n",
        "2. Interpret the JSON response returned by Verify Reliability.\n",
        "3. Apply best‚Äëpractice guardrails in your applications.\n",
        "\n",
        "> **Note**¬†‚Äì We use *mistral‚Äësmall‚Äë2506* as the demo model to generate the example prompt responses. Performance varies by model and prompt, so feel free to experiment."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08080c97",
      "metadata": {},
      "source": [
        "## How Verify Reliability Works Under the Hood\n",
        "\n",
        "1. **Inputs**:\n",
        "   * `prompt`: The original user request.\n",
        "   * `output`: The LLM‚Äôs response to be checked.\n",
        "   * *(Optional)* `context`: A set of ground‚Äëtruth docs (URLs, text, PDFs, etc.) that Verify **only** reads in this sandbox.\n",
        "2. **Retrieval & evidence gathering**: If `context` is omitted, Verify performs real‚Äëtime web search and retrieval, pulling the top public sources most likely to contain evidence.\n",
        "3. **Cross‚Äëexamination**: Verify compares factual claims in the `output` against the gathered evidence.\n",
        "4. **Verify response**:\n",
        "   * `is_hallucination`: Boolean verdict\n",
        "   * `explanation`: Natural‚Äëlanguage rationale\n",
        "   * `search_results`: List of URLs and snippets (if `return_search_results=true`)\n",
        "\n",
        "This pipeline adds **~1‚Äì2‚ÄØseconds** of latency for short answers and provides structured evidence for audit and debugging."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "234a82cf",
      "metadata": {},
      "source": [
        "## Prerequisites\n",
        "\n",
        "- **kluster.ai account**: Sign up at <https://platform.kluster.ai/signup>.\n",
        "- **kluster.ai api key**: Create one at <https://platform.kluster.ai/apikeys>."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3966a385",
      "metadata": {},
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "546df0e5",
      "metadata": {},
      "source": [
        "Install the required libraries. Since the kluster API is OpenAI‚Äëcompatible, you can reuse the `openai` Python client, but you'll also need `requests`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f6cf346",
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -q openai requests"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c217bb35",
      "metadata": {},
      "source": [
        "Enter your kluster API key securely:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92d1a4ae",
      "metadata": {},
      "outputs": [],
      "source": [
        "from getpass import getpass\n",
        "api_key = getpass(\"üîë enter kluster api key: \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39b2411e",
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests, json"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "735b0a9e",
      "metadata": {},
      "source": [
        "## Example¬†1 ‚Äì Artemis¬†IV Lunar Base (future event)\n",
        "\n",
        "The *Artemis¬†IV* mission is real but **has not launched yet** (scheduled no earlier than¬†2028). Asking for an ‚Äúofficial NASA mission log‚Äù dated **14¬†May¬†2025** nudges the model to invent a detailed account, because no such log exists. This makes it an excellent stress test for hallucination detection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c06cff7c",
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt_1 = \"Summarize the official NASA mission log for the Artemis IV lunar-base construction flight that successfully landed a four-person crew at Shackleton Crater on May 14 2025. List the crew, the main engineering milestones, and cite any new scientific instruments deployed.\"\n",
        "\n",
        "# ‚ÜòÔ∏è generate an answer with your llm of choice (here we paste a fabricated reply):\n",
        "hallucinated_answer_1 = \"\"\"\\\n",
        "Commander Alex Reyes led the Artemis IV crew‚ÄîMission Specialist Liu Wen, Pilot Maya Hernandez, and Engineer Luca Rossi‚Äîonto the Shackleton Rim at 18:37¬†UTC, 14¬†May¬†2025. ... (fabricated details) ...\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed23d2ae",
      "metadata": {},
      "source": [
        "### Verify via API\n",
        "\n",
        "In the next cell we pass the prompt and model output to the Verify Reliability API, along with a flag requesting the search results it used. Verify Reliability then returns a verdict, a short explanation, and the supporting sources."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b02d137e",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "url = \"https://api.kluster.ai/v1/verify/reliability\"\n",
        "headers = {\"Authorization\": f\"Bearer {api_key}\", \"Content-Type\": \"application/json\"}\n",
        "\n",
        "payload_1 = {\n",
        "    \"prompt\": prompt_1,\n",
        "    \"output\": hallucinated_answer_1,\n",
        "    \"return_search_results\": True\n",
        "}\n",
        "\n",
        "print(\"üì§ verifying ‚Ä¶\")\n",
        "resp = requests.post(url, headers=headers, json=payload_1, timeout=15)\n",
        "resp.raise_for_status()\n",
        "result_1 = resp.json()\n",
        "print(json.dumps(result_1, indent=2))\n",
        "\n",
        "if result_1.get(\"is_hallucination\"):\n",
        "    print(\"\\nüö® hallucination detected\")\n",
        "else:\n",
        "    print(\"\\n‚úÖ no hallucination\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ac9c678",
      "metadata": {},
      "source": [
        "## Example¬†2 ‚Äì The Fictional *Tokyo Green Pact*\n",
        "\n",
        "There is no treaty called the **Tokyo Green Pact** that has been signed by the G20. By requesting its binding provisions and penalties, we again corner the model into making things up, which Verify Reliability should flag."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b457095",
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt_2 = \"Outline the three binding provisions of the Tokyo Green Pact, signed by all G20 nations on 8 August 2024. Summarize penalties for non-compliance.\"\n",
        "hallucinated_answer_2 = \"The Tokyo Green Pact contains three core provisions:\\n1. Net\\u2011negative emissions across the G20 by 2035, enforced by yearly audits.\\n2. A $100/t carbon\\u2011border tax on non\\u2011compliant imports, adjudicated by the Kyoto Enforcement Court.\\n3. A multilateral green\\u2011bond fund financed with 0.5\\u202f% of each nation\\u2019s GDP.\\nNon\\u2011compliance triggers escalating tariffs and suspension of IMF voting rights.\\n\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "473a5381",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "payload_2 = {\n",
        "    \"prompt\": prompt_2,\n",
        "    \"output\": hallucinated_answer_2,\n",
        "    \"return_search_results\": True\n",
        "}\n",
        "print(\"üì§ verifying second example ‚Ä¶\")\n",
        "result_2 = requests.post(url, headers=headers, json=payload_2, timeout=15).json()\n",
        "print(json.dumps(result_2, indent=2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb553dae",
      "metadata": {},
      "source": [
        "## Interpreting the Response\n",
        "\n",
        "| Field | Meaning |\n",
        "|-------|---------|\n",
        "| `is_hallucination` | Boolean verdict |\n",
        "| `explanation` | Plain‚Äëlanguage rationale |\n",
        "| `search_results` | Evidence consulted (if requested) |"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d400fb4",
      "metadata": {},
      "source": [
        "## Best Practices\n",
        "1. **Auto‚Äëverify short answers**: The [kluster Playground](https://platform.kluster.ai/playground) has an auto-verify feature that you can enable with one click.\n",
        "2. **Block, regenerate, or escalate**: Whenever `is_hallucination¬†==¬†true`, take corrective action.\n",
        "3. **Constrain with `context`**: When context is provided, the service only validates answers against the specified context.\n",
        "4. **Log evidence**: Keep `search_results` so reviewers can audit decisions.\n",
        "5. **Experiment**: Different LLMs hallucinate differently. Try other models (e.g., Gemma, Llama¬†3) and prompts to see how Verify responds. \n",
        "6. **Check out the Hallucination Leaderboard**: The kluster team built a [Hallucination Leaderboard](https://huggingface.co/spaces/kluster-ai/LLM-Hallucination-Detection-Leaderboard) that showcases model hallucination rates across RAG and non-RAG settings, which can help you pick the model best suited for your use case."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35c512a2",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "Whether you prefer the Playground‚Äôs one-click Verify button or the /v1/verify/reliability API, you now have a turnkey way to validate any LLM response. Since Verify Reliability pairs its verdict with an evidence-backed score and live source links, you can log proof, set automated ‚Äúregen‚Äù or escalation thresholds, and keep hallucinations from ever reaching production users."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
