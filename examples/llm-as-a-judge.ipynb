{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be189fde-4e5b-4f80-bae1-ded86a5075a7",
   "metadata": {
    "id": "be189fde-4e5b-4f80-bae1-ded86a5075a7"
   },
   "source": [
    "# Evaluating LLM performance without ground truth using an LLM judge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17a77d9",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/kluster-ai/klusterai-cookbook/blob/main/examples/llm-as-a-judge.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355a788f-a618-42a2-98c1-3d0e68ff766c",
   "metadata": {},
   "source": [
    "How can we test a model's accuracy when the ground truth is unavailable? One approach could be to test the predictions made by the base model against a larger model, which, comparatively, should do better.\n",
    "\n",
    "This tutorial uses a base model (`Llama-3.1-8B-Instruct-Turbo`) to classify a dataset based on a description. Next, we will use a larger model (`klusterai/Meta-Llama-3.3-70B-Instruct-Turbo`) as a judge, tasked to determine whether the base model's predictions are correct. Since the dataset also contains the ground truth, the notebook also assesses how well the judge model performed.\n",
    "\n",
    "A great breakdown on calculating a model's accuracy can be found in our <a href=\"/tutorials/klusterai-api/model-comparison/\" target=\"_blank\"> model comparison notebook</a>.\n",
    "\n",
    "You'll be using the same dataset as in our <a href=\"/tutorials/klusterai-api/text-classification/text-classification-openai-api/\" target=\"_blank\">text classification notebook</a>, which is an extract from the IMDB top 1000 movies dataset categorized into 21 different genres.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Before getting started, ensure you have the following:\n",
    "\n",
    "- **A kluster.ai account** - sign up on the <a href=\"https://platform.kluster.ai/signup\" target=\"_blank\">kluster.ai platform</a> if you don't have one\n",
    "- **A kluster.ai API key** - after signing in, go to the <a href=\"https://platform.kluster.ai/apikeys\" target=\"_blank\">**API Keys**</a> section and create a new key. For detailed instructions, check out the <a href=\"/get-started/get-api-key/\" target=\"_blank\">Get an API key</a> guide\n",
    "\n",
    "## Setup\n",
    "\n",
    "In this notebook, we'll use Python's `getpass` module to input the key safely. After execution, please provide your unique kluster.ai API key (ensure no spaces)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4911e5eb-7463-4a6b-8a99-9313cecd9d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your kluster.ai API key:  ········\n"
     ]
    }
   ],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "api_key = getpass(\"Enter your kluster.ai API key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b786c1f-360a-4929-80d5-cf57fdc5d3c7",
   "metadata": {},
   "source": [
    "Next, ensure you've installed the OpenAI Python library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcc3d475-8f49-4fc4-9a5e-c6eb6866d2b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca8f9a8-a368-4c1b-b4f2-95b232099981",
   "metadata": {},
   "source": [
    "With the OpenAI Python library installed, we import the necessary dependencies for the tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b89a4feb-37a9-430d-a742-cd58495b4eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465e7cfd-1265-4501-b34e-9dac359bf785",
   "metadata": {},
   "source": [
    "Then, initialize the `client` by pointing it to the kluster.ai endpoint and passing your API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "zG9y_WO5rYaj",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the client\n",
    "client = OpenAI(\n",
    "    base_url=\"https://api.kluster.ai/v1\",\n",
    "    api_key=api_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1e29b4-4bbd-4cd2-b65c-723041c911e2",
   "metadata": {},
   "source": [
    "## Get the data\n",
    "\n",
    "Now that you've initialized an OpenAI-compatible client pointing to kluster.ai, we can talk about the data.\n",
    "\n",
    "This notebook uses a dataset from the Top 1000 IMDb Movies dataset, which contains descriptions and genres for each movie. In some cases, a movie can have more than one label. When calculating the accuracy, we'll consider the prediction correct if the predicted genre matches at least one of the genres listed in the dataset, the ground truth. This ground truth allows the notebook to calculate the accuracy and measure how well a given LLM has performed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2de9a5fe-9ebc-4c3a-8455-fdb66bd1771e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Series_Title</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Overview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>Drama</td>\n",
       "      <td>Two imprisoned men bond over a number of years...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>Crime, Drama</td>\n",
       "      <td>An organized crime dynasty's aging patriarch t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>Action, Crime, Drama</td>\n",
       "      <td>When the menace known as the Joker wreaks havo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Series_Title                 Genre  \\\n",
       "0  The Shawshank Redemption                 Drama   \n",
       "1             The Godfather          Crime, Drama   \n",
       "2           The Dark Knight  Action, Crime, Drama   \n",
       "\n",
       "                                            Overview  \n",
       "0  Two imprisoned men bond over a number of years...  \n",
       "1  An organized crime dynasty's aging patriarch t...  \n",
       "2  When the menace known as the Joker wreaks havo...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IMDB Top 1000 dataset:\n",
    "url = \"https://raw.githubusercontent.com/kluster-ai/klusterai-cookbook/refs/heads/main/data/imdb_top_1000.csv\"\n",
    "urllib.request.urlretrieve(url,filename='imdb_top_1000.csv')\n",
    "\n",
    "# Load and process the dataset based on URL content\n",
    "df = pd.read_csv('imdb_top_1000.csv', usecols=['Series_Title', 'Overview', 'Genre'])\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d30ad63-8b1e-4b67-8d1c-621be45a9c23",
   "metadata": {},
   "source": [
    "## Perform batch inference\n",
    "\n",
    "To execute the batch inference job, we'll create the following functions:\n",
    "\n",
    "1. **Create the batch job file** - we'll generate a JSON lines file with the desired requests to be processed by the model. Consequently, we'll create a file for the assistant model and one for the judge model. You can also work with a single file by providing the different models for each request\n",
    "2. **Upload the batch job file** - once it is ready, we'll upload it to the <a href=\"https://platform.kluster.ai/signup\" target=\"_blank\">kluster.ai platform</a> using the API, where it will be processed. We'll receive a unique ID associated with our file\n",
    "3. **Start the batch job** - after the file is uploaded, we'll initiate the job to process the uploaded data, using the file ID obtained before\n",
    "4. **Monitor job progress** - (optional) track the status of the batch job to ensure it has been successfully completed\n",
    "5. **Retrieve results** - once the job has completed execution, we can access and process the resultant data\n",
    "\n",
    "Next, we will run the functions for the base model and feed the results to the pipeline using the judge model.\n",
    "\n",
    "This notebook is prepared for you to follow along. Run the cells below to watch it all come together.\n",
    "\n",
    "### Create the batch job file\n",
    "\n",
    "The following snippets prepare the JSONL file, where each line represents a different request. The function is set to reuse between the base and judge models.\n",
    "\n",
    "Note that each separate batch request can have its own model. Also, we are using a temperature of `0.5`, but feel free to change it and play around with the different outcomes (but we are only asking to respond with a single word, the genre)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0903230-7384-4d7f-98dc-1c1c705c2933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the directory exists\n",
    "os.makedirs(\"llm_as_judge\", exist_ok=True)\n",
    "\n",
    "# Create the batch job file with the prompt and content for the model\n",
    "def create_batch_file(index, model, system_prompt, content):\n",
    "\n",
    "    request = {\n",
    "        \"custom_id\": f\"{model}-{index}-analysis\",\n",
    "        \"method\": \"POST\",\n",
    "        \"url\": \"/v1/chat/completions\",\n",
    "        \"body\": {\n",
    "            \"model\": model,\n",
    "            \"temperature\": 0.5,\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": content},\n",
    "            ],\n",
    "        },\n",
    "    }\n",
    "\n",
    "    return request\n",
    "\n",
    "\n",
    "# Save file\n",
    "def save_batch_file(batch_list, model):\n",
    "    filename = f\"llm_as_judge/batch_job_{model}_request.jsonl\"\n",
    "    with open(filename, \"w\") as file:\n",
    "        for request in batch_list:\n",
    "            file.write(json.dumps(request) + \"\\n\")\n",
    "    return filename\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabae7d0-4d1e-431a-98b4-4caed514d4d0",
   "metadata": {},
   "source": [
    "### Upload batch job file to kluster.ai\n",
    "\n",
    "Once we've prepared our input file, it's time to upload them to the kluster.ai platform. To do so, you can use the `files.create` endpoint of the client, where the purpose is set to `batch`. This will return the file ID, which we need to log for the next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89408bd4-51b2-490e-b5ce-da002c41921c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_batch_file(data_dir):\n",
    "  print(f\"Creating request for {data_dir}\")\n",
    "  \n",
    "  with open(data_dir, 'rb') as file:\n",
    "    upload_response = client.files.create(\n",
    "    file=file,\n",
    "    purpose=\"batch\"\n",
    "  )\n",
    "\n",
    "  # Print job ID\n",
    "  file_id = upload_response.id\n",
    "  print(f\"File uploaded successfully. File ID: {file_id}\")\n",
    "\n",
    "  return upload_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee042b2-aed6-423d-8581-e56b3aeb312d",
   "metadata": {},
   "source": [
    "### Start the job\n",
    "\n",
    "Once all the files have been successfully uploaded, we're ready to start (create) the batch jobs by providing the file ID. To start each job, we use the `batches.create` method, for which we need to set the endpoint to `/v1/chat/completions`. This will return each batch job's details, with each ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef3e5446-ad11-4d4f-8c02-e27e32905445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create batch job with completions endpoint\n",
    "def create_batch_job(file_id):\n",
    "  batch_job = client.batches.create(\n",
    "    input_file_id=file_id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\"\n",
    "  )\n",
    "\n",
    "  print(f\"Batch job created with ID {batch_job.id}\")\n",
    "  return batch_job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb0c8a4-5666-4740-88ea-e5633bc7e2d5",
   "metadata": {},
   "source": [
    "### Check job progress\n",
    "\n",
    "Once your batch jobs have been created, you can track their progress.\n",
    "\n",
    "To monitor the job's progress, we can use the `batches.retrieve` method and pass the batch job ID. The response contains a `status` field that tells whether it is completed and the subsequent status of each job separately. We can repeat this process for every batch job ID we get in the previous step.\n",
    "\n",
    "The following snippet checks the status of all batch jobs every 10 seconds until the entire batch is completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72c2c7ba-d933-4ebe-997d-6d529292e21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def monitor_batch_job(job):\n",
    "    completed = False\n",
    "\n",
    "    # Loop until all jobs are completed\n",
    "    while not completed:\n",
    "        completed = True\n",
    "\n",
    "        updated_job = client.batches.retrieve(job.id)\n",
    "        status = updated_job.status\n",
    "\n",
    "        # If job is completed\n",
    "        if status == \"completed\":\n",
    "            msg = f\"Job ended with status: {status}\"\n",
    "            print(f\"\\r{msg}{' ' * (80 - len(msg))}\", end=\"\", flush=True)\n",
    "            break\n",
    "        # If job failed, cancelled or expired\n",
    "        elif status in [\"failed\", \"cancelled\", \"expired\"]:\n",
    "            print(f\"\\rJob ended with status: {status}\")\n",
    "            break\n",
    "        # If job is ongoing\n",
    "        else:\n",
    "            completed = False\n",
    "            current_completed = updated_job.request_counts.completed\n",
    "            total = updated_job.request_counts.total\n",
    "            msg = f\"Job status: {status} - Progress: {current_completed}/{total}\"\n",
    "            print(f\"\\r{msg}{' ' * (80 - len(msg))}\", end=\"\", flush=True)\n",
    "\n",
    "        # Check every 5 seconds\n",
    "        if not completed:\n",
    "            time.sleep(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac21c8ec-284f-4d46-8e43-b1a6cdab0425",
   "metadata": {},
   "source": [
    "### Get the results\n",
    "\n",
    "When the batch job is completed, we'll retrieve the results and review the responses generated for each request. The results are parsed. To fetch the results from the platform, you must retrieve the `output_file_id` from the batch job and then use the `files.content` endpoint, providing that specific file ID. We will repeat this for every single batch job id. Note that the job status must be `completed` to retrieve the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e23944f9-9f8d-477c-9bd6-0667e9def190",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parse results as a JSON object\n",
    "def parse_json_objects(data_string):\n",
    "    if isinstance(data_string, bytes):\n",
    "        data_string = data_string.decode('utf-8')\n",
    "\n",
    "    json_strings = data_string.strip().split('\\n')\n",
    "    json_objects = []\n",
    "\n",
    "    for json_str in json_strings:\n",
    "        try:\n",
    "            json_obj = json.loads(json_str)\n",
    "            json_objects.append(json_obj)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error parsing JSON: {e}\")\n",
    "\n",
    "    return json_objects\n",
    "\n",
    "# Retrieve results with job ID\n",
    "def retrieve_results(batch_job):\n",
    "    job = client.batches.retrieve(batch_job.id)\n",
    "    result_file_id = job.output_file_id\n",
    "    result = client.files.content(result_file_id).content\n",
    "\n",
    "    # Parse JSON results\n",
    "    parsed_result = parse_json_objects(result)\n",
    "\n",
    "    answers = []\n",
    "    # Extract the content of each response\n",
    "    for item in parsed_result:\n",
    "        try:\n",
    "            content = item[\"response\"][\"body\"][\"choices\"][0][\"message\"][\"content\"]\n",
    "            answers.append(content)\n",
    "        except KeyError as e:\n",
    "            print(f\"Missing key in response: {e}\")\n",
    "    return answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669c99c7-9d84-4fbb-b410-181464500af3",
   "metadata": {},
   "source": [
    "Now that the basic inference pipeline has been established, let's run it first for the base model.\n",
    "\n",
    "## Batch inference for the base model\n",
    "\n",
    "This example uses Llama 3.1 8B as the base model. If you'd like to test different models, feel free to modify the scripts accordingly.\n",
    "\n",
    "Please refer to the <a href=\"/get-started/models/#model-comparison-table\" target=\"_blank\">Supported models</a> section for a list of the models we support.\n",
    "\n",
    "For the base model, the prompt is pretty similar to that of the <a href=\"/tutorials/klusterai-api/text-classification/text-classification-openai-api/\" target=\"_blank\">text classification notebook</a>, where we ask to classify each movie genre based on a description, and providing a specific set of options as possible genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0787daf6-8386-4829-96b4-fea90df02808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch file created llm_as_judge/batch_job_Llama3.1-8B-Base_request.jsonl\n",
      "Creating request for llm_as_judge/batch_job_Llama3.1-8B-Base_request.jsonl\n",
      "File uploaded successfully. File ID: 681df4e8c92de30bfdc7d1aa\n",
      "Batch job created with ID 681df4e8c39f51afee4d7adf\n",
      "Job ended with status: completed                                                "
     ]
    }
   ],
   "source": [
    "# System prompt\n",
    "SYSTEM_PROMPT_BASE = \"\"\"\n",
    "    You are a helpful assistant who classifies movie genres based on the provided description. Choose one of the following options: \n",
    "    Action, Adventure, Animation, Biography, Comedy, Crime, Drama, Family, Fantasy, Film-Noir, History, Horror, Music, Musical, Mystery, Romance, Sci-Fi, Sport, Thriller, War, Western.\n",
    "    Provide your response as a single word with the matching genre. Don't include punctuation.\n",
    "    \"\"\"\n",
    "\n",
    "# Model\n",
    "model_name = \"Llama3.1-8B-Base\"\n",
    "model = \"klusterai/Meta-Llama-3.1-8B-Instruct-Turbo\"\n",
    "\n",
    "# Create batch file\n",
    "batch_list = []\n",
    "for index, row in df.iterrows():\n",
    "    content = row[\"Overview\"]\n",
    "    batch_list.append(create_batch_file(index, model, SYSTEM_PROMPT_BASE, content))\n",
    "filename = save_batch_file(batch_list, model_name)\n",
    "print(f\"Batch file created {filename}\")\n",
    "\n",
    "# Upload batch file\n",
    "batch_file = upload_batch_file(filename)\n",
    "\n",
    "# Create batch job\n",
    "batch_job = create_batch_job(batch_file.id)\n",
    "\n",
    "# Monitor batch job\n",
    "monitor_batch_job(batch_job)\n",
    "\n",
    "# Save results\n",
    "df['Predicted_Genre_Base_Model'] = retrieve_results(batch_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4908c0-7224-4f9f-81fc-4774d47d153b",
   "metadata": {},
   "source": [
    "Next, let's print the first three predictions made by the base model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "426dbf80-2f88-44eb-937c-2124961f6474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Series_Title</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Overview</th>\n",
       "      <th>Predicted_Genre_Base_Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>Drama</td>\n",
       "      <td>Two imprisoned men bond over a number of years...</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>Crime, Drama</td>\n",
       "      <td>An organized crime dynasty's aging patriarch t...</td>\n",
       "      <td>Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>Action, Crime, Drama</td>\n",
       "      <td>When the menace known as the Joker wreaks havo...</td>\n",
       "      <td>Superhero</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Series_Title                 Genre  \\\n",
       "0  The Shawshank Redemption                 Drama   \n",
       "1             The Godfather          Crime, Drama   \n",
       "2           The Dark Knight  Action, Crime, Drama   \n",
       "\n",
       "                                            Overview  \\\n",
       "0  Two imprisoned men bond over a number of years...   \n",
       "1  An organized crime dynasty's aging patriarch t...   \n",
       "2  When the menace known as the Joker wreaks havo...   \n",
       "\n",
       "  Predicted_Genre_Base_Model  \n",
       "0                      Drama  \n",
       "1                      Crime  \n",
       "2                  Superhero  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the first 3 genre predictions\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d85e21-384e-4c27-8658-1ef56538bee2",
   "metadata": {},
   "source": [
    "With the base model inference performed, let's move to the judge model inference.\n",
    "\n",
    "## Batch inference for the judge model\n",
    "\n",
    "This example uses the larger Llama 3.3 70B as the judge model (the artificial ground truth). If you'd like to test different models, feel free to modify the scripts accordingly.\n",
    "\n",
    "Please refer to the <a href=\"/get-started/models/#model-comparison-table\" target=\"_blank\">Supported models</a> section for a list of the models we support.\n",
    "\n",
    "For the judge model, we must be very specific about the task to be executed, providing unambiguous guidelines on what constitutes a correct and incorrect prediction by the base model. For example, you must also consider cases in which the base model offers a response that is not formatted correctly. You might need to tune each prompt to ensure the judge model accurately measures the base model response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c028a4cd-9c86-4119-b46b-69669c7eff18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch file created llm_as_judge/batch_job_Llama3.3-70B-Judge_request.jsonl\n",
      "Creating request for llm_as_judge/batch_job_Llama3.3-70B-Judge_request.jsonl\n",
      "File uploaded successfully. File ID: 681df517030fcc793229acbd\n",
      "Batch job created with ID 681df51861f50fed2032f44d\n",
      "Job ended with status: completed                                                "
     ]
    }
   ],
   "source": [
    "# System prompt\n",
    "SYSTEM_PROMPT_JUDGE = \"\"\"\n",
    "    You will receive a movie description, a list of possible genres, and a predicted movie genre made by another LLM (base model).\n",
    "    Your task is to evaluate whether the predicted genre is ‘correct’ or ‘incorrect’ based on the following steps and requirements.\n",
    "    \n",
    "    Steps to Follow:\n",
    "    1. Carefully read the movie description.\n",
    "    2. Determine your own classification of the genre for the movie. Do not rely on the base model answer since it may be incorrect.\n",
    "    3. Do not rely on individual words to identify the genre; read the whole description to identify the genre.\n",
    "    4. Read the base model answer (enclosed in double quotes) and evaluate if it is correct by following the Evaluation Criteria below.\n",
    "    5. Provide your evaluation as 'correct' or 'incorrect'.\n",
    "    \n",
    "    Evaluation Criteria:\n",
    "    - If the base model answer (enclosed in double quotes) does not align with the movie description, the evaluation should be ‘incorrect’.\n",
    "    - The first letter of the base model answer (enclosed in double quotes) must be capitalized (e.g., Drama). If it has any other capitalization, the evaluation should be ‘incorrect’.\n",
    "    - All other letters in the base model answer (enclosed in double quotes) must be lowercase. Otherwise, the evaluation should be ‘incorrect’.\n",
    "    - If the base model answer consists of multiple words, the evaluation should be ‘incorrect’.\n",
    "    - If the base model answer includes punctuation, spaces, or additional characters, the evaluation should be ‘incorrect’.\n",
    "    - If the base model answer (enclosed in double quotes) is not one of the provided genres, the evaluation should be ‘incorrect’. \n",
    "    - If it is not listed, the evaluation should be ‘incorrect’.\n",
    "    \n",
    "    Output Rules:\n",
    "    - Provide your genre prediction and evaluation without additional text, punctuation, or explanation.\n",
    "    - The output must be: the genre prediction and the evaluation. The first letter uppercase and all other letters lowercase.\n",
    "    \n",
    "    Final Answer Format:\n",
    "    Prediction,Evaluation\n",
    "    \n",
    "    Example:\n",
    "    Drama,Correct\n",
    "    \"\"\"\n",
    "\n",
    "# Model\n",
    "model_name = \"Llama3.3-70B-Judge\"\n",
    "model = \"klusterai/Meta-Llama-3.3-70B-Instruct-Turbo\"\n",
    "\n",
    "# Create batch file\n",
    "batch_list = []\n",
    "for index, row in df.iterrows():\n",
    "\n",
    "    # Message content for judging\n",
    "    content = f\"\"\"\n",
    "        Movie Description: {row['Overview']}.\n",
    "        Available Genres: Action, Adventure, Animation, Biography, Comedy, Crime, Drama, Family, Fantasy, Film-Noir, History, Horror, Music, Musical, Mystery, Romance, Sci-Fi, Sport, Thriller, War, Western\n",
    "        Base model answer: \"{row['Predicted_Genre_Base_Model']}\"\n",
    "        \"\"\"\n",
    "    batch_list.append(create_batch_file(index, model, SYSTEM_PROMPT_JUDGE, content))\n",
    "    \n",
    "filename = save_batch_file(batch_list, model_name)\n",
    "print(f\"Batch file created {filename}\")\n",
    "\n",
    "\n",
    "# Upload batch file\n",
    "batch_file = upload_batch_file(filename)\n",
    "\n",
    "# Create batch job\n",
    "batch_job = create_batch_job(batch_file.id)\n",
    "\n",
    "# Monitor batch job\n",
    "monitor_batch_job(batch_job)\n",
    "\n",
    "# Save results\n",
    "df['Judge_Prediction_Evaluation'] = retrieve_results(batch_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf25a9bd-95cc-4dcc-9053-51d65d41590f",
   "metadata": {},
   "source": [
    "Next, let's print the first 10 predictions with the evaluation from the judge model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "285597a1-7b03-4036-a8f9-6ad98c0ce28d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Series_Title</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Overview</th>\n",
       "      <th>Predicted_Genre_Base_Model</th>\n",
       "      <th>Judge_Prediction_Evaluation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>Drama</td>\n",
       "      <td>Two imprisoned men bond over a number of years...</td>\n",
       "      <td>Drama</td>\n",
       "      <td>Drama,Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>Crime, Drama</td>\n",
       "      <td>An organized crime dynasty's aging patriarch t...</td>\n",
       "      <td>Crime</td>\n",
       "      <td>Drama,Incorrect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>Action, Crime, Drama</td>\n",
       "      <td>When the menace known as the Joker wreaks havo...</td>\n",
       "      <td>Superhero</td>\n",
       "      <td>Action,Incorrect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Godfather: Part II</td>\n",
       "      <td>Crime, Drama</td>\n",
       "      <td>The early life and career of Vito Corleone in ...</td>\n",
       "      <td>Crime</td>\n",
       "      <td>Crime,Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12 Angry Men</td>\n",
       "      <td>Crime, Drama</td>\n",
       "      <td>A jury holdout attempts to prevent a miscarria...</td>\n",
       "      <td>Mystery</td>\n",
       "      <td>Drama,Incorrect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Lord of the Rings: The Return of the King</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>Gandalf and Aragorn lead the World of Men agai...</td>\n",
       "      <td>Fantasy</td>\n",
       "      <td>Fantasy,Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pulp Fiction</td>\n",
       "      <td>Crime, Drama</td>\n",
       "      <td>The lives of two mob hitmen, a boxer, a gangst...</td>\n",
       "      <td>Crime</td>\n",
       "      <td>Crime,Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Schindler's List</td>\n",
       "      <td>Biography, Drama, History</td>\n",
       "      <td>In German-occupied Poland during World War II,...</td>\n",
       "      <td>Drama</td>\n",
       "      <td>History,Incorrect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Inception</td>\n",
       "      <td>Action, Adventure, Sci-Fi</td>\n",
       "      <td>A thief who steals corporate secrets through t...</td>\n",
       "      <td>Thriller</td>\n",
       "      <td>Sci-Fi,Incorrect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fight Club</td>\n",
       "      <td>Drama</td>\n",
       "      <td>An insomniac office worker and a devil-may-car...</td>\n",
       "      <td>Drama</td>\n",
       "      <td>Thriller,Incorrect</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Series_Title                      Genre  \\\n",
       "0                       The Shawshank Redemption                      Drama   \n",
       "1                                  The Godfather               Crime, Drama   \n",
       "2                                The Dark Knight       Action, Crime, Drama   \n",
       "3                         The Godfather: Part II               Crime, Drama   \n",
       "4                                   12 Angry Men               Crime, Drama   \n",
       "5  The Lord of the Rings: The Return of the King   Action, Adventure, Drama   \n",
       "6                                   Pulp Fiction               Crime, Drama   \n",
       "7                               Schindler's List  Biography, Drama, History   \n",
       "8                                      Inception  Action, Adventure, Sci-Fi   \n",
       "9                                     Fight Club                      Drama   \n",
       "\n",
       "                                            Overview  \\\n",
       "0  Two imprisoned men bond over a number of years...   \n",
       "1  An organized crime dynasty's aging patriarch t...   \n",
       "2  When the menace known as the Joker wreaks havo...   \n",
       "3  The early life and career of Vito Corleone in ...   \n",
       "4  A jury holdout attempts to prevent a miscarria...   \n",
       "5  Gandalf and Aragorn lead the World of Men agai...   \n",
       "6  The lives of two mob hitmen, a boxer, a gangst...   \n",
       "7  In German-occupied Poland during World War II,...   \n",
       "8  A thief who steals corporate secrets through t...   \n",
       "9  An insomniac office worker and a devil-may-car...   \n",
       "\n",
       "  Predicted_Genre_Base_Model Judge_Prediction_Evaluation  \n",
       "0                      Drama               Drama,Correct  \n",
       "1                      Crime             Drama,Incorrect  \n",
       "2                  Superhero            Action,Incorrect  \n",
       "3                      Crime               Crime,Correct  \n",
       "4                    Mystery             Drama,Incorrect  \n",
       "5                    Fantasy             Fantasy,Correct  \n",
       "6                      Crime               Crime,Correct  \n",
       "7                      Drama           History,Incorrect  \n",
       "8                   Thriller            Sci-Fi,Incorrect  \n",
       "9                      Drama          Thriller,Incorrect  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the first 10 judge evaluations\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626e0642-4ee7-4afd-950d-22fbdff9fb84",
   "metadata": {},
   "source": [
    "## Analysis of the LLM as a judge\n",
    "\n",
    "In the previous sections we first defined a batch inference pipeline. Next, we ran that inference pipeline using a base model, requesting it to predict the genre of a movie based of a brief overview/description. Lastly, we ran another batch inference using a judge model, asking the model to evaluate the results of the base model in accordance to its own prediction.\n",
    "\n",
    "To analyze the accuracy of the base model using the judge model as ground truth, we can count the number of `correct` evaluations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c053021-99ed-4143-bed4-580fd93b01de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Judge-determined accuracy:  0.592\n"
     ]
    }
   ],
   "source": [
    "# Extract the evaluation from judge model\n",
    "df[\"Evaluation\"] = df[\"Judge_Prediction_Evaluation\"].str.split(\",\").str[1].str.strip()\n",
    "print('LLM Judge-determined accuracy: ', (df[\"Evaluation\"].str.lower() == \"correct\").mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f75c0f9-b3c7-4aa0-baae-6e9f5a0f0c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model ground truth determined accuracy: 0.725\n",
      "Judge model ground truth determined accuracy: 0.767\n"
     ]
    }
   ],
   "source": [
    "# Clean Genre data\n",
    "df[\"Actual_Genres_List\"] = df[\"Genre\"].str.split(\",\").apply(lambda genres: [g.strip() for g in genres])\n",
    "\n",
    "# Base model compared to ground truth\n",
    "df[\"Base_Eval\"] = df.apply(lambda row: row[\"Predicted_Genre_Base_Model\"] in row[\"Actual_Genres_List\"], axis=1)\n",
    "\n",
    "# Extract the predicted genre from judge model\n",
    "df[\"Judge_Predicted_Genre\"] = df[\"Judge_Prediction_Evaluation\"].str.split(\",\").str[0].str.strip()\n",
    "\n",
    "# Judge model compared to ground truth\n",
    "df[\"Judge_Eval\"] = df.apply(lambda row: row[\"Judge_Predicted_Genre\"] in row[\"Actual_Genres_List\"], axis=1)\n",
    "\n",
    "print(f\"Base model ground truth determined accuracy: {df[\"Base_Eval\"].mean()}\")\n",
    "print(f\"Judge model ground truth determined accuracy: {df[\"Judge_Eval\"].mean()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ecd20b-fda8-4ad4-bd30-bf4d434ee469",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This tutorial used the chat completion endpoint to perform genre classification on movie descriptions from the IMDb Top 1000 dataset using the kluster.ai batch API. Additionally, we used a larger language model to generate a synthetic ground truth, enabling us to evaluate the base model's performance better.\n",
    "\n",
    "First, we built a pipeline to submit batch jobs and retrieve results using the base model. We then applied the same pipeline with a larger \"judge\" model, which evaluated whether the base model's genre predictions were correct, based on strict formatting and semantic criteria.\n",
    "\n",
    "Finally, we compared three types of accuracy (results may vary depending on each notebook execution):\n",
    "- Base model accuracy against LLM ground truth: 59.2%  \n",
    "- Base model accuracy against real ground truth: 72.5%  \n",
    "- Judge model accuracy against real ground truth: 76.7%\n",
    "\n",
    "These results show that while the base model achieved moderate accuracy when compared to human-annotated ground truth, it performed significantly worse when judged by the larger model. This suggests that the judge model applies stricter or more nuanced evaluation criteria. Notably, the judge model achieved the highest accuracy compared to the real ground truth.\n",
    "\n",
    "As next steps, feel free to create your own dataset, or expand on top of this existing example. Good luck!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
