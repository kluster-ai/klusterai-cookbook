{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "be189fde-4e5b-4f80-bae1-ded86a5075a7",
      "metadata": {
        "id": "be189fde-4e5b-4f80-bae1-ded86a5075a7"
      },
      "source": [
        "# Text classification with kluster.ai API and Bespoke Curator"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b17a77d9",
      "metadata": {
        "id": "b17a77d9"
      },
      "source": [
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/kluster-ai/klusterai-cookbook/blob/main/examples/text-classification/text-classification-curator.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d1d06ea-79c1-4f28-b312-0e5aabe18ff3",
      "metadata": {
        "id": "6d1d06ea-79c1-4f28-b312-0e5aabe18ff3"
      },
      "source": [
        "This notebook goes through the same example as in our previous <a href=\"/tutorials/klusterai-api/text-classification-api/\" target=\"_blank\">Text classification notebook</a>, but this time, we'll be using Bespoke Curator instead of the OpenAI Python library\n",
        "\n",
        "To recap, the notebook uses <a href=\"https://kluster.ai/\" target=\"_blank\">kluster.ai</a> batch API to classify a data set based on a predefined set of categories.\n",
        "\n",
        "The example uses an extract from the IMDB top 1000 movies dataset and categorizes them into \"Action,\" \"Adventure,\" \"Comedy,\" \"Crime,\" \"Documentary,\" \"Drama,\" \"Fantasy,\" \"Horror,\" \"Romance,\" or \"Sci-Fi.\"\n",
        "\n",
        "You can adapt this example by using your data and categories relevant to your use case. With this approach, you can effortlessly process datasets of any scale, big or small, and obtain categorized results powered by a state-of-the-art language model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0349537",
      "metadata": {
        "id": "d0349537"
      },
      "source": [
        "## Prerequisites\n",
        "\n",
        "Before getting started, ensure you have the following:\n",
        "\n",
        "- **A kluster.ai account** - sign up on the <a href=\"https://platform.kluster.ai/signup\" target=\"_blank\">kluster.ai platform</a> if you don't have one\n",
        "- **A kluster.ai API key** - after signing in, go to the <a href=\"https://platform.kluster.ai/apikeys\" target=\"_blank\">**API Keys**</a> section and create a new key. For detailed instructions, check out the <a href=\"/get-started/get-api-key/\" target=\"_blank\">Get an API key</a> guide"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xU1WBQJ7Uh09",
      "metadata": {
        "id": "xU1WBQJ7Uh09"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8d580f8-67d5-45d6-915f-0f6b60d3b543",
      "metadata": {
        "id": "b8d580f8-67d5-45d6-915f-0f6b60d3b543"
      },
      "source": [
        "In this notebook, we'll use Python's `getpass` module to input the key safely. After execution, please provide your unique kluster.ai API key (ensure no spaces)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "4911e5eb-7463-4a6b-8a99-9313cecd9d4d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4911e5eb-7463-4a6b-8a99-9313cecd9d4d",
        "outputId": "d5a95816-c6d7-4af1-e857-f3e430aaf643"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your kluster.ai API key: ··········\n"
          ]
        }
      ],
      "source": [
        "from getpass import getpass\n",
        "api_key = getpass(\"Enter your kluster.ai API key: \")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PLlUhTtGH_Fx",
      "metadata": {
        "id": "PLlUhTtGH_Fx"
      },
      "source": [
        "Next, ensure you've the Bespoke Curator Python library:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "bcc3d475-8f49-4fc4-9a5e-c6eb6866d2b5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcc3d475-8f49-4fc4-9a5e-c6eb6866d2b5",
        "outputId": "85c18736-4b57-420c-a814-ccff645a7ec4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: google-cloud-aiplatform 1.71.1 does not provide the extra 'all'\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "pip install -q bespokelabs-curator"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "VLDS32DeIb-N",
      "metadata": {
        "id": "VLDS32DeIb-N"
      },
      "source": [
        "Now that we've the library, we can initialize the LLM object for batch. Note that Curator supports kluster.ai natively, so you just need to provide the model to use, API key, and completion window.\n",
        "\n",
        "This example uses `klusterai/Meta-Llama-3.1-8B-Instruct-Turbo`, but feel free to comment it and uncomment any other model you want to try out."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "zG9y_WO5rYaj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zG9y_WO5rYaj",
        "outputId": "b6404367-7caf-4602-9398-feb8c761fcce"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG:curator.bespokelabs.curator.log:Adjusting file descriptor limit from 1048576 to 1048576 (hard limit: 1048576)\n"
          ]
        }
      ],
      "source": [
        "from bespokelabs import curator\n",
        "\n",
        "# Models\n",
        "#model=\"deepseek-ai/DeepSeek-R1\"\n",
        "#model=\"deepseek-ai/DeepSeek-V3\"\n",
        "model=\"klusterai/Meta-Llama-3.1-8B-Instruct-Turbo\"\n",
        "#model=\"klusterai/Meta-Llama-3.1-405B-Instruct-Turbo\"\n",
        "#model=\"klusterai/Meta-Llama-3.3-70B-Instruct-Turbo\"\n",
        "#model=\"Qwen/Qwen2.5-VL-7B-Instruct\"\n",
        "\n",
        "llm = curator.LLM(\n",
        "    model_name=model,\n",
        "    batch=True,\n",
        "    backend=\"klusterai\",\n",
        "    backend_params={\"api_key\": api_key, \"completion_window\": \"24h\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "udPtLfTaisSw",
      "metadata": {
        "id": "udPtLfTaisSw"
      },
      "source": [
        "## Get the data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QjCVfg65jKz6",
      "metadata": {
        "id": "QjCVfg65jKz6"
      },
      "source": [
        "With the Curator LLM object ready, let's define the data and prompt.\n",
        "\n",
        "This notebook includes a preloaded sample dataset derived from the Top 1000 IMDb Movies dataset. It contains movie descriptions ready for classification. No additional setup is needed. Proceed to the next steps to begin working with this data.\n",
        "\n",
        "For this particular scenario, the prompt consists of the request to the model and the data (movie) to be classified. Because this is a batch job, each separate request must contain both."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "dA9TL6wwr-VS",
      "metadata": {
        "id": "dA9TL6wwr-VS"
      },
      "outputs": [],
      "source": [
        "movies = [\"Breakfast at Tiffany's: A young New York socialite becomes interested in a young man who has moved into her apartment building, but her past threatens to get in the way.\",\n",
        "        \"Giant: Sprawling epic covering the life of a Texas cattle rancher and his family and associates.\",\n",
        "        \"From Here to Eternity: In Hawaii in 1941, a private is cruelly punished for not boxing on his unit's team, while his captain's wife and second-in-command are falling in love.\",\n",
        "        \"Lifeboat: Several survivors of a torpedoed merchant ship in World War II find themselves in the same lifeboat with one of the crew members of the U-boat that sank their ship.\",\n",
        "        \"The 39 Steps: A man in London tries to help a counter-espionage Agent. But when the Agent is killed, and the man stands accused, he must go on the run to save himself and stop a spy ring which is trying to steal top secret information.\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "r35Ztc4NsVuW",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r35Ztc4NsVuW",
        "outputId": "261cee03-74c9-43b1-811f-67b58e829bf6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classify the main genre of the given movie description based on the following genres(Respond with only the genre): “Action”, “Adventure”, “Comedy”, “Crime”, “Documentary”, “Drama”, “Fantasy”, “Horror”, “Romance”, “Sci-Fi”.\n",
            "Breakfast at Tiffany's: A young New York socialite becomes interested in a young man who has moved into her apartment building, but her past threatens to get in the way.\n",
            "Classify the main genre of the given movie description based on the following genres(Respond with only the genre): “Action”, “Adventure”, “Comedy”, “Crime”, “Documentary”, “Drama”, “Fantasy”, “Horror”, “Romance”, “Sci-Fi”.\n",
            "Giant: Sprawling epic covering the life of a Texas cattle rancher and his family and associates.\n",
            "Classify the main genre of the given movie description based on the following genres(Respond with only the genre): “Action”, “Adventure”, “Comedy”, “Crime”, “Documentary”, “Drama”, “Fantasy”, “Horror”, “Romance”, “Sci-Fi”.\n",
            "From Here to Eternity: In Hawaii in 1941, a private is cruelly punished for not boxing on his unit's team, while his captain's wife and second-in-command are falling in love.\n",
            "Classify the main genre of the given movie description based on the following genres(Respond with only the genre): “Action”, “Adventure”, “Comedy”, “Crime”, “Documentary”, “Drama”, “Fantasy”, “Horror”, “Romance”, “Sci-Fi”.\n",
            "Lifeboat: Several survivors of a torpedoed merchant ship in World War II find themselves in the same lifeboat with one of the crew members of the U-boat that sank their ship.\n",
            "Classify the main genre of the given movie description based on the following genres(Respond with only the genre): “Action”, “Adventure”, “Comedy”, “Crime”, “Documentary”, “Drama”, “Fantasy”, “Horror”, “Romance”, “Sci-Fi”.\n",
            "The 39 Steps: A man in London tries to help a counter-espionage Agent. But when the Agent is killed, and the man stands accused, he must go on the run to save himself and stop a spy ring which is trying to steal top secret information.\n"
          ]
        }
      ],
      "source": [
        "prompts = [f\"Classify the main genre of the given movie description based on the following genres(Respond with only the genre): “Action”, “Adventure”, “Comedy”, “Crime”, “Documentary”, “Drama”, “Fantasy”, “Horror”, “Romance”, “Sci-Fi”.\\n{movie}\" for movie in movies]\n",
        "\n",
        "# Log the prompt\n",
        "for prompt in prompts:\n",
        "    print(prompt)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "OyGuHllZllct",
      "metadata": {
        "id": "OyGuHllZllct"
      },
      "source": [
        "## Perform batch inference with Curator"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64c345aa-b6a7-4770-8368-b290e9e799dc",
      "metadata": {
        "id": "64c345aa-b6a7-4770-8368-b290e9e799dc"
      },
      "source": [
        "\n",
        "\n",
        "Now that everything is set, we can execute the inference job. With Curator it is extremely simple, we just need to pass the prompts to the LLM object, and log the response."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "qqIgWWCn4MIJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "19e4418a0edd484487ab3ce2c2ad28d1",
            "26710d3ecfa4406faf1c4164cf50a4fb",
            "6e163498af57412790eb498f7abd9765",
            "50786dbdef5644a6bbcea4744c7ba45a",
            "264e77364c274ce6b401a45cf0492044",
            "de13df6edf044023901993f113084f8d",
            "937f45453fbf4d8884e29e54ed30b324",
            "a6e3ab9f5591492f8e14920673dc5b27",
            "42e1a96add5b4bc3a9bd0650a42c8212",
            "6098b41bf78240cdab475713c6bdad7a",
            "c2b1d5e01f1b453d834c3eb2ada8c101",
            "bec77dccd0d14485a760137d4bdc1aef",
            "b8cbf8e283034f7e8ac9a22811ef7344",
            "b4f5c41c72634e93913a9e6abd060b5a",
            "1a592861545e46369d21acda969a660a",
            "a1e77f67facd4d1493f45d74f34aea70",
            "92f1fbc1424c46db81559fe41711c364",
            "3b89e61ef99b4d6082fb54797b065228",
            "58724ca6ef814d82be0f9ec0a2b42c3d",
            "23eb24c8f9e844b2ba01defa0aa5dd30",
            "a2edec59a12d4a70a95852c76b4db3a5",
            "d5269d5e84e542a88909642e3576bed7",
            "24499253917d4b10b6835a5c0aa95f55",
            "b611d9e156954ea186c5f1df4f4356b8"
          ]
        },
        "id": "qqIgWWCn4MIJ",
        "outputId": "2469d86f-6825-4f23-a13d-4c8d36498838"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "19e4418a0edd484487ab3ce2c2ad28d1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG:curator.bespokelabs.curator.log:Curator Cache Fingerprint String: 36e766fc298f4350_5ac272e3bc92b32e_klusterai/Meta-Llama-3.1-8B-Instruct-Turbo_text_True\n",
            "DEBUG:curator.bespokelabs.curator.log:Curator Cache Fingerprint: 3acb0d5efbda6beb\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[03/24/25 09:51:35] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Running OpenAIBatchRequestProcessor completions with     <a href=\"file:///usr/local/lib/python3.11/dist-packages/bespokelabs/curator/request_processor/base_request_processor.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base_request_processor.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///usr/local/lib/python3.11/dist-packages/bespokelabs/curator/request_processor/base_request_processor.py#130\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">130</span></a>\n",
              "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         model: klusterai/Meta-Llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.1</span>-8B-Instruct-Turbo        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                             </span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m[03/24/25 09:51:35]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Running OpenAIBatchRequestProcessor completions with     \u001b]8;id=775680;file:///usr/local/lib/python3.11/dist-packages/bespokelabs/curator/request_processor/base_request_processor.py\u001b\\\u001b[2mbase_request_processor.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=70261;file:///usr/local/lib/python3.11/dist-packages/bespokelabs/curator/request_processor/base_request_processor.py#130\u001b\\\u001b[2m130\u001b[0m\u001b]8;;\u001b\\\n",
              "\u001b[2;36m                    \u001b[0m         model: klusterai/Meta-Llama-\u001b[1;36m3.1\u001b[0m-8B-Instruct-Turbo        \u001b[2m                             \u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:curator.bespokelabs.curator.log:Running OpenAIBatchRequestProcessor completions with model: klusterai/Meta-Llama-3.1-8B-Instruct-Turbo\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Preparing request <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">file</span><span style=\"font-weight: bold\">(</span>s<span style=\"font-weight: bold\">)</span> in                             <a href=\"file:///usr/local/lib/python3.11/dist-packages/bespokelabs/curator/request_processor/base_request_processor.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base_request_processor.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///usr/local/lib/python3.11/dist-packages/bespokelabs/curator/request_processor/base_request_processor.py#230\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">230</span></a>\n",
              "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #800080; text-decoration-color: #800080\">/root/.cache/curator/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">3acb0d5efbda6beb</span>                    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                             </span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Preparing request \u001b[1;35mfile\u001b[0m\u001b[1m(\u001b[0ms\u001b[1m)\u001b[0m in                             \u001b]8;id=653565;file:///usr/local/lib/python3.11/dist-packages/bespokelabs/curator/request_processor/base_request_processor.py\u001b\\\u001b[2mbase_request_processor.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=418546;file:///usr/local/lib/python3.11/dist-packages/bespokelabs/curator/request_processor/base_request_processor.py#230\u001b\\\u001b[2m230\u001b[0m\u001b]8;;\u001b\\\n",
              "\u001b[2;36m                    \u001b[0m         \u001b[35m/root/.cache/curator/\u001b[0m\u001b[95m3acb0d5efbda6beb\u001b[0m                    \u001b[2m                             \u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:curator.bespokelabs.curator.log:Preparing request file(s) in /root/.cache/curator/3acb0d5efbda6beb\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Wrote <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> requests to                                      <a href=\"file:///usr/local/lib/python3.11/dist-packages/bespokelabs/curator/request_processor/base_request_processor.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base_request_processor.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///usr/local/lib/python3.11/dist-packages/bespokelabs/curator/request_processor/base_request_processor.py#312\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">312</span></a>\n",
              "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #800080; text-decoration-color: #800080\">/root/.cache/curator/3acb0d5efbda6beb/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">requests_0.jsonl.</span>  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                             </span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Wrote \u001b[1;36m5\u001b[0m requests to                                      \u001b]8;id=742458;file:///usr/local/lib/python3.11/dist-packages/bespokelabs/curator/request_processor/base_request_processor.py\u001b\\\u001b[2mbase_request_processor.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=785142;file:///usr/local/lib/python3.11/dist-packages/bespokelabs/curator/request_processor/base_request_processor.py#312\u001b\\\u001b[2m312\u001b[0m\u001b]8;;\u001b\\\n",
              "\u001b[2;36m                    \u001b[0m         \u001b[35m/root/.cache/curator/3acb0d5efbda6beb/\u001b[0m\u001b[95mrequests_0.jsonl.\u001b[0m  \u001b[2m                             \u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:curator.bespokelabs.curator.log:Wrote 5 requests to /root/.cache/curator/3acb0d5efbda6beb/requests_0.jsonl.\n",
            "DEBUG:curator.bespokelabs.curator.log:Batch file content size: 0.00 MB (3,367 bytes)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bec77dccd0d14485a760137d4bdc1aef",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG:curator.bespokelabs.curator.log:skipping uploaded file status check, provider does not support file checks.\n",
            "DEBUG:curator.bespokelabs.curator.log:File uploaded with id 67e12b272d9e5ba243fe9ba1\n",
            "DEBUG:curator.bespokelabs.curator.log:Batch submitted with id 67e12b286afe1d706e726f73\n",
            "DEBUG:curator.bespokelabs.curator.log:Marked /root/.cache/curator/3acb0d5efbda6beb/requests_0.jsonl as submitted with batch 67e12b286afe1d706e726f73\n",
            "DEBUG:curator.bespokelabs.curator.log:Updated submitted batch 67e12b286afe1d706e726f73 with new request counts\n",
            "DEBUG:curator.bespokelabs.curator.log:Batch 67e12b286afe1d706e726f73 status: in_progress requests: 0/0/5 succeeded/failed/total\n",
            "DEBUG:curator.bespokelabs.curator.log:Batches returned: 0/1 Requests completed: 0/5\n",
            "DEBUG:curator.bespokelabs.curator.log:Sleeping for 60 seconds...\n",
            "DEBUG:curator.bespokelabs.curator.log:Updated submitted batch 67e12b286afe1d706e726f73 with new request counts\n",
            "DEBUG:curator.bespokelabs.curator.log:Batch 67e12b286afe1d706e726f73 status: completed requests: 5/0/5 succeeded/failed/total\n",
            "DEBUG:curator.bespokelabs.curator.log:Batch 67e12b286afe1d706e726f73 finished with status: completed\n",
            "DEBUG:curator.bespokelabs.curator.log:Marked batch 67e12b286afe1d706e726f73 as finished\n",
            "DEBUG:curator.bespokelabs.curator.log:Batch 67e12b286afe1d706e726f73 completed and downloaded\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
              "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
              "To authenticate with the Hugging Face Hub, create a token in your settings tab \n",
              "(https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
              "You will be able to reuse this secret in all of your notebooks.\n",
              "Please note that authentication is recommended but still optional to access public models or datasets.\n",
              "  warnings.warn(\n",
              "</pre>\n"
            ],
            "text/plain": [
              "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
              "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
              "To authenticate with the Hugging Face Hub, create a token in your settings tab \n",
              "(https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
              "You will be able to reuse this secret in all of your notebooks.\n",
              "Please note that authentication is recommended but still optional to access public models or datasets.\n",
              "  warnings.warn(\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b4f5c41c72634e93913a9e6abd060b5a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.08M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG:curator.bespokelabs.curator.log:Batch 67e12b286afe1d706e726f73 written to /root/.cache/curator/3acb0d5efbda6beb/responses_0.jsonl\n",
            "DEBUG:curator.bespokelabs.curator.log:Marked batch 67e12b286afe1d706e726f73 as downloaded\n",
            "DEBUG:curator.bespokelabs.curator.log:Batches returned: 1/1 Requests completed: 5/5\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">•</span> Time Elapsed <span style=\"color: #808000; text-decoration-color: #808000\">0:01:04</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">•</span> Time Remaining <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[1;37m•\u001b[0m Time Elapsed \u001b[33m0:01:04\u001b[0m \u001b[1;37m•\u001b[0m Time Remaining \u001b[36m0:00:00\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">Curator Viewer:</span> <span style=\"color: #808000; text-decoration-color: #808000\">Disabled</span>                                                            \n",
              "Set <span style=\"color: #808000; text-decoration-color: #808000\">HOSTED_CURATOR_VIEWER=</span><span style=\"color: #008080; text-decoration-color: #008080\">1</span> to view your data live at <span style=\"color: #000080; text-decoration-color: #000080\">https://curator.bespokelabs.ai</span>\n",
              "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">Batches:</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Total:</span> <span style=\"color: #000080; text-decoration-color: #000080\">1</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">•</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Submitted:</span> <span style=\"color: #808000; text-decoration-color: #808000\">0⋯</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">•</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Downloaded:</span> <span style=\"color: #008000; text-decoration-color: #008000\">1✓</span>                                  \n",
              "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">Requests:</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Total:</span> <span style=\"color: #000080; text-decoration-color: #000080\">5</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">•</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Submitted:</span> <span style=\"color: #808000; text-decoration-color: #808000\">0⋯</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">•</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Succeeded:</span> <span style=\"color: #008000; text-decoration-color: #008000\">5✓</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">•</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Failed:</span> <span style=\"color: #800000; text-decoration-color: #800000\">0✗</span>                     \n",
              "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">Tokens:</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Avg Input:</span> <span style=\"color: #000080; text-decoration-color: #000080\">133</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">•</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Avg Output:</span> <span style=\"color: #000080; text-decoration-color: #000080\">7</span>                                              \n",
              "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">Cost:</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Current:</span> <span style=\"color: #800080; text-decoration-color: #800080\">$0.000</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">•</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Projected:</span> <span style=\"color: #800080; text-decoration-color: #800080\">$0.000</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">•</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Rate:</span> <span style=\"color: #800080; text-decoration-color: #800080\">$0.000/request</span>                    \n",
              "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">Model:</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Name:</span> <span style=\"color: #000080; text-decoration-color: #000080\">klusterai/Meta-Llama-3.1-8B-Instruct-Turbo</span>                             \n",
              "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">Model Pricing:</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Per 1M tokens:</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Input:</span> <span style=\"color: #800000; text-decoration-color: #800000\">$0.050</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">•</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Output:</span> <span style=\"color: #800000; text-decoration-color: #800000\">$0.050</span>                        \n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1;37mCurator Viewer:\u001b[0m \u001b[33mDisabled\u001b[0m                                                            \n",
              "Set \u001b[33mHOSTED_CURATOR_VIEWER=\u001b[0m\u001b[36m1\u001b[0m to view your data live at \u001b[34mhttps://curator.bespokelabs.ai\u001b[0m\n",
              "\u001b[1;37mBatches:\u001b[0m \u001b[37mTotal:\u001b[0m \u001b[34m1\u001b[0m \u001b[37m•\u001b[0m \u001b[37mSubmitted:\u001b[0m \u001b[33m0⋯\u001b[0m \u001b[37m•\u001b[0m \u001b[37mDownloaded:\u001b[0m \u001b[32m1✓\u001b[0m                                  \n",
              "\u001b[1;37mRequests:\u001b[0m \u001b[37mTotal:\u001b[0m \u001b[34m5\u001b[0m \u001b[37m•\u001b[0m \u001b[37mSubmitted:\u001b[0m \u001b[33m0⋯\u001b[0m \u001b[37m•\u001b[0m \u001b[37mSucceeded:\u001b[0m \u001b[32m5✓\u001b[0m \u001b[37m•\u001b[0m \u001b[37mFailed:\u001b[0m \u001b[31m0✗\u001b[0m                     \n",
              "\u001b[1;37mTokens:\u001b[0m \u001b[37mAvg Input:\u001b[0m \u001b[34m133\u001b[0m \u001b[37m•\u001b[0m \u001b[37mAvg Output:\u001b[0m \u001b[34m7\u001b[0m                                              \n",
              "\u001b[1;37mCost:\u001b[0m \u001b[37mCurrent:\u001b[0m \u001b[35m$0.000\u001b[0m \u001b[37m•\u001b[0m \u001b[37mProjected:\u001b[0m \u001b[35m$0.000\u001b[0m \u001b[37m•\u001b[0m \u001b[37mRate:\u001b[0m \u001b[35m$0.000/request\u001b[0m                    \n",
              "\u001b[1;37mModel:\u001b[0m \u001b[37mName:\u001b[0m \u001b[34mklusterai/Meta-Llama-3.1-8B-Instruct-Turbo\u001b[0m                             \n",
              "\u001b[1;37mModel Pricing:\u001b[0m \u001b[37mPer 1M tokens:\u001b[0m \u001b[37mInput:\u001b[0m \u001b[31m$0.050\u001b[0m \u001b[37m•\u001b[0m \u001b[37mOutput:\u001b[0m \u001b[31m$0.050\u001b[0m                        \n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                         Final Curator Statistics                          </span>\n",
              "╭────────────────────────────┬────────────────────────────────────────────╮\n",
              "│<span style=\"font-weight: bold\"> Section/Metric             </span>│<span style=\"font-weight: bold\"> Value                                      </span>│\n",
              "├────────────────────────────┼────────────────────────────────────────────┤\n",
              "│<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Model                      </span>│<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">                                            </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Model                      </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> </span><span style=\"color: #000080; text-decoration-color: #000080\">klusterai/Meta-Llama-3.1-8B-Instruct-Turbo</span><span style=\"color: #808000; text-decoration-color: #808000\"> </span>│\n",
              "│<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Batches                    </span>│<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">                                            </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Total Batches              </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> 1                                          </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Submitted                  </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> 0                                          </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Downloaded                 </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> </span><span style=\"color: #008000; text-decoration-color: #008000\">1</span><span style=\"color: #808000; text-decoration-color: #808000\">                                          </span>│\n",
              "│<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Requests                   </span>│<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">                                            </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Total Requests             </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> 5                                          </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Successful                 </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> </span><span style=\"color: #008000; text-decoration-color: #008000\">5</span><span style=\"color: #808000; text-decoration-color: #808000\">                                          </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Failed                     </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> </span><span style=\"color: #800000; text-decoration-color: #800000\">0</span><span style=\"color: #808000; text-decoration-color: #808000\">                                          </span>│\n",
              "│<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Tokens                     </span>│<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">                                            </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Total Tokens Used          </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> 0                                          </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Total Input Tokens         </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> 664                                        </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Total Output Tokens        </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> 35                                         </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Average Tokens per Request </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> 0                                          </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Average Input Tokens       </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> 132                                        </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Average Output Tokens      </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> 7                                          </span>│\n",
              "│<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Costs                      </span>│<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">                                            </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Total Cost                 </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> </span><span style=\"color: #800000; text-decoration-color: #800000\">$0.000</span><span style=\"color: #808000; text-decoration-color: #808000\">                                     </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Average Cost per Request   </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> </span><span style=\"color: #800000; text-decoration-color: #800000\">$0.000</span><span style=\"color: #808000; text-decoration-color: #808000\">                                     </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Input Cost per 1M Tokens   </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> </span><span style=\"color: #800000; text-decoration-color: #800000\">$0.050</span><span style=\"color: #808000; text-decoration-color: #808000\">                                     </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Output Cost per 1M Tokens  </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> </span><span style=\"color: #800000; text-decoration-color: #800000\">$0.050</span><span style=\"color: #808000; text-decoration-color: #808000\">                                     </span>│\n",
              "│<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Performance                </span>│<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">                                            </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Total Time                 </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> 64.37s                                     </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Average Time per Request   </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> 12.87s                                     </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Requests per Minute        </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> 4.7                                        </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Input Tokens per Minute    </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> 618.9                                      </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Output Tokens per Minute   </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> 32.6                                       </span>│\n",
              "╰────────────────────────────┴────────────────────────────────────────────╯\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[3m                         Final Curator Statistics                          \u001b[0m\n",
              "╭────────────────────────────┬────────────────────────────────────────────╮\n",
              "│\u001b[1m \u001b[0m\u001b[1mSection/Metric            \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1mValue                                     \u001b[0m\u001b[1m \u001b[0m│\n",
              "├────────────────────────────┼────────────────────────────────────────────┤\n",
              "│\u001b[1;35m \u001b[0m\u001b[1;35mModel                     \u001b[0m\u001b[1;35m \u001b[0m│\u001b[1;35m \u001b[0m\u001b[1;35m                                          \u001b[0m\u001b[1;35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mModel                     \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[34mklusterai/Meta-Llama-3.1-8B-Instruct-Turbo\u001b[0m\u001b[33m \u001b[0m│\n",
              "│\u001b[1;35m \u001b[0m\u001b[1;35mBatches                   \u001b[0m\u001b[1;35m \u001b[0m│\u001b[1;35m \u001b[0m\u001b[1;35m                                          \u001b[0m\u001b[1;35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mTotal Batches             \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m1                                         \u001b[0m\u001b[33m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mSubmitted                 \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m0\u001b[0m\u001b[33m                                         \u001b[0m\u001b[33m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mDownloaded                \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[32m1\u001b[0m\u001b[33m                                         \u001b[0m\u001b[33m \u001b[0m│\n",
              "│\u001b[1;35m \u001b[0m\u001b[1;35mRequests                  \u001b[0m\u001b[1;35m \u001b[0m│\u001b[1;35m \u001b[0m\u001b[1;35m                                          \u001b[0m\u001b[1;35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mTotal Requests            \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m5                                         \u001b[0m\u001b[33m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mSuccessful                \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[32m5\u001b[0m\u001b[33m                                         \u001b[0m\u001b[33m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mFailed                    \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[31m0\u001b[0m\u001b[33m                                         \u001b[0m\u001b[33m \u001b[0m│\n",
              "│\u001b[1;35m \u001b[0m\u001b[1;35mTokens                    \u001b[0m\u001b[1;35m \u001b[0m│\u001b[1;35m \u001b[0m\u001b[1;35m                                          \u001b[0m\u001b[1;35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mTotal Tokens Used         \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m0                                         \u001b[0m\u001b[33m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mTotal Input Tokens        \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m664                                       \u001b[0m\u001b[33m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mTotal Output Tokens       \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m35                                        \u001b[0m\u001b[33m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mAverage Tokens per Request\u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m0                                         \u001b[0m\u001b[33m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mAverage Input Tokens      \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m132                                       \u001b[0m\u001b[33m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mAverage Output Tokens     \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m7                                         \u001b[0m\u001b[33m \u001b[0m│\n",
              "│\u001b[1;35m \u001b[0m\u001b[1;35mCosts                     \u001b[0m\u001b[1;35m \u001b[0m│\u001b[1;35m \u001b[0m\u001b[1;35m                                          \u001b[0m\u001b[1;35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mTotal Cost                \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[31m$0.000\u001b[0m\u001b[33m                                    \u001b[0m\u001b[33m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mAverage Cost per Request  \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[31m$0.000\u001b[0m\u001b[33m                                    \u001b[0m\u001b[33m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mInput Cost per 1M Tokens  \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[31m$0.050\u001b[0m\u001b[33m                                    \u001b[0m\u001b[33m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mOutput Cost per 1M Tokens \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[31m$0.050\u001b[0m\u001b[33m                                    \u001b[0m\u001b[33m \u001b[0m│\n",
              "│\u001b[1;35m \u001b[0m\u001b[1;35mPerformance               \u001b[0m\u001b[1;35m \u001b[0m│\u001b[1;35m \u001b[0m\u001b[1;35m                                          \u001b[0m\u001b[1;35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mTotal Time                \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m64.37s                                    \u001b[0m\u001b[33m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mAverage Time per Request  \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m12.87s                                    \u001b[0m\u001b[33m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mRequests per Minute       \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m4.7                                       \u001b[0m\u001b[33m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mInput Tokens per Minute   \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m618.9                                     \u001b[0m\u001b[33m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mOutput Tokens per Minute  \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m32.6                                      \u001b[0m\u001b[33m \u001b[0m│\n",
              "╰────────────────────────────┴────────────────────────────────────────────╯\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[03/24/25 09:52:39] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Read <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> responses.                                        <a href=\"file:///usr/local/lib/python3.11/dist-packages/bespokelabs/curator/request_processor/base_request_processor.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base_request_processor.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///usr/local/lib/python3.11/dist-packages/bespokelabs/curator/request_processor/base_request_processor.py#437\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">437</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m[03/24/25 09:52:39]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Read \u001b[1;36m5\u001b[0m responses.                                        \u001b]8;id=540187;file:///usr/local/lib/python3.11/dist-packages/bespokelabs/curator/request_processor/base_request_processor.py\u001b\\\u001b[2mbase_request_processor.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=807916;file:///usr/local/lib/python3.11/dist-packages/bespokelabs/curator/request_processor/base_request_processor.py#437\u001b\\\u001b[2m437\u001b[0m\u001b]8;;\u001b\\\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:curator.bespokelabs.curator.log:Read 5 responses.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Finalizing writer                                        <a href=\"file:///usr/local/lib/python3.11/dist-packages/bespokelabs/curator/request_processor/base_request_processor.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base_request_processor.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///usr/local/lib/python3.11/dist-packages/bespokelabs/curator/request_processor/base_request_processor.py#446\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">446</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Finalizing writer                                        \u001b]8;id=275061;file:///usr/local/lib/python3.11/dist-packages/bespokelabs/curator/request_processor/base_request_processor.py\u001b\\\u001b[2mbase_request_processor.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=388337;file:///usr/local/lib/python3.11/dist-packages/bespokelabs/curator/request_processor/base_request_processor.py#446\u001b\\\u001b[2m446\u001b[0m\u001b]8;;\u001b\\\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:curator.bespokelabs.curator.log:Finalizing writer\n"
          ]
        }
      ],
      "source": [
        "responses = llm(prompts)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5650dde",
      "metadata": {},
      "source": [
        "Lastly, let's print the response."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "xKhW-uXy4X32",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKhW-uXy4X32",
        "outputId": "37af6cf3-044c-451f-ef9f-a61d3bfb0d56"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Romance',\n",
              " 'Drama',\n",
              " 'Drama',\n",
              " 'Drama',\n",
              " 'Thriller is a possible genre but choosing an option from the above categories, it would be \"Drama\"']"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "responses['response']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70e0e816-6558-4ff2-bab2-f85cff00bfc8",
      "metadata": {
        "id": "70e0e816-6558-4ff2-bab2-f85cff00bfc8"
      },
      "source": [
        "## Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d195dd1-1293-4407-b6ad-cab7e77b14c0",
      "metadata": {
        "id": "7d195dd1-1293-4407-b6ad-cab7e77b14c0"
      },
      "source": [
        "This tutorial used the chat completion endpoint and Bespoke Curator to perform a simple text classification task with batch inference. This particular example clasified a series of movies based on their description.\n",
        "\n",
        "Using Curator, submitting a batch job is extremely simple. It handles all the steps of creating the file, uploading it, submitting the batch job, monitoring the job, and retrieving results. Moreover, kluster.ai is natively supported, making things even easier!\n",
        "\n",
        "\n",
        "Kluster.ai's batch API empowers you to scale your workflows seamlessly, making it an invaluable tool for processing extensive datasets. As next steps, feel free to create your own dataset, or expand on top of this existing example. Good luck!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
