{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be189fde-4e5b-4f80-bae1-ded86a5075a7",
   "metadata": {
    "id": "be189fde-4e5b-4f80-bae1-ded86a5075a7"
   },
   "source": [
    "# Text classification with kluster.ai API and Bespoke Curator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17a77d9",
   "metadata": {
    "id": "b17a77d9"
   },
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/kluster-ai/klusterai-cookbook/blob/main/examples/text-classification/text-classification-curator.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1d06ea-79c1-4f28-b312-0e5aabe18ff3",
   "metadata": {
    "id": "6d1d06ea-79c1-4f28-b312-0e5aabe18ff3"
   },
   "source": [
    "This notebook goes through the same example as in our previous <a href=\"/tutorials/klusterai-api/text-classification-api/\" target=\"_blank\">Text classification notebook</a>, but this time, we'll be using Bespoke Curator instead of the OpenAI Python library\n",
    "\n",
    "To recap, the notebook uses <a href=\"https://kluster.ai/\" target=\"_blank\">kluster.ai</a> batch API to classify a data set based on a predefined set of categories.\n",
    "\n",
    "The example uses an extract from the IMDB top 1000 movies dataset and categorizes them into \"Action,\" \"Adventure,\" \"Comedy,\" \"Crime,\" \"Documentary,\" \"Drama,\" \"Fantasy,\" \"Horror,\" \"Romance,\" or \"Sci-Fi.\"\n",
    "\n",
    "You can adapt this example by using your data and categories relevant to your use case. With this approach, you can effortlessly process datasets of any scale, big or small, and obtain categorized results powered by a state-of-the-art language model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0349537",
   "metadata": {
    "id": "d0349537"
   },
   "source": [
    "## Prerequisites\n",
    "\n",
    "Before getting started, ensure you have the following:\n",
    "\n",
    "- **A kluster.ai account** - sign up on the <a href=\"https://platform.kluster.ai/signup\" target=\"_blank\">kluster.ai platform</a> if you don't have one\n",
    "- **A kluster.ai API key** - after signing in, go to the <a href=\"https://platform.kluster.ai/apikeys\" target=\"_blank\">**API Keys**</a> section and create a new key. For detailed instructions, check out the <a href=\"/get-started/get-api-key/\" target=\"_blank\">Get an API key</a> guide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xU1WBQJ7Uh09",
   "metadata": {
    "id": "xU1WBQJ7Uh09"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d580f8-67d5-45d6-915f-0f6b60d3b543",
   "metadata": {
    "id": "b8d580f8-67d5-45d6-915f-0f6b60d3b543"
   },
   "source": [
    "In this notebook, we'll use Python's `getpass` module to input the key safely. After execution, please provide your unique kluster.ai API key (ensure no spaces)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4911e5eb-7463-4a6b-8a99-9313cecd9d4d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4911e5eb-7463-4a6b-8a99-9313cecd9d4d",
    "outputId": "d5a95816-c6d7-4af1-e857-f3e430aaf643"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your kluster.ai API key:  ········\n"
     ]
    }
   ],
   "source": [
    "from getpass import getpass\n",
    "api_key = getpass(\"Enter your kluster.ai API key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PLlUhTtGH_Fx",
   "metadata": {
    "id": "PLlUhTtGH_Fx"
   },
   "source": [
    "Next, ensure you've the Bespoke Curator Python library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcc3d475-8f49-4fc4-9a5e-c6eb6866d2b5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bcc3d475-8f49-4fc4-9a5e-c6eb6866d2b5",
    "outputId": "85c18736-4b57-420c-a814-ccff645a7ec4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: google-cloud-aiplatform 1.71.1 does not provide the extra 'all'\u001b[0m\u001b[33m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q bespokelabs-curator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VLDS32DeIb-N",
   "metadata": {
    "id": "VLDS32DeIb-N"
   },
   "source": [
    "Now that we've the library, we can initialize the LLM object for batch. Note that Curator supports kluster.ai natively, so you just need to provide the model to use, API key, and completion window.\n",
    "\n",
    "This example uses `klusterai/Meta-Llama-3.1-8B-Instruct-Turbo`, but feel free to comment it and uncomment any other model you want to try out.\n",
    "\n",
    "Please refer to the <a href=\"/get-started/models/\" target=\"_blank\">Supported models</a> section for a list of the models we support.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "zG9y_WO5rYaj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zG9y_WO5rYaj",
    "outputId": "b6404367-7caf-4602-9398-feb8c761fcce"
   },
   "outputs": [],
   "source": [
    "from bespokelabs import curator\n",
    "\n",
    "# Models\n",
    "#model=\"deepseek-ai/DeepSeek-R1\"\n",
    "#model=\"deepseek-ai/DeepSeek-V3-0324\"\n",
    "model=\"klusterai/Meta-Llama-3.1-8B-Instruct-Turbo\"\n",
    "#model=\"klusterai/Meta-Llama-3.3-70B-Instruct-Turbo\"\n",
    "#model=\"Qwen/Qwen2.5-VL-7B-Instruct\"\n",
    "\n",
    "llm = curator.LLM(\n",
    "    model_name=model,\n",
    "    batch=True,\n",
    "    backend=\"klusterai\",\n",
    "    backend_params={\"api_key\": api_key, \"completion_window\": \"24h\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "udPtLfTaisSw",
   "metadata": {
    "id": "udPtLfTaisSw"
   },
   "source": [
    "## Get the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QjCVfg65jKz6",
   "metadata": {
    "id": "QjCVfg65jKz6"
   },
   "source": [
    "With the Curator LLM object ready, let's define the data and prompt.\n",
    "\n",
    "This notebook includes a preloaded sample dataset derived from the Top 1000 IMDb Movies dataset. It contains movie descriptions ready for classification. No additional setup is needed. Proceed to the next steps to begin working with this data.\n",
    "\n",
    "For this particular scenario, the prompt consists of the request to the model and the data (movie) to be classified. Because this is a batch job, each separate request must contain both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dA9TL6wwr-VS",
   "metadata": {
    "id": "dA9TL6wwr-VS"
   },
   "outputs": [],
   "source": [
    "movies = [\"Breakfast at Tiffany's: A young New York socialite becomes interested in a young man who has moved into her apartment building, but her past threatens to get in the way.\",\n",
    "        \"Giant: Sprawling epic covering the life of a Texas cattle rancher and his family and associates.\",\n",
    "        \"From Here to Eternity: In Hawaii in 1941, a private is cruelly punished for not boxing on his unit's team, while his captain's wife and second-in-command are falling in love.\",\n",
    "        \"Lifeboat: Several survivors of a torpedoed merchant ship in World War II find themselves in the same lifeboat with one of the crew members of the U-boat that sank their ship.\",\n",
    "        \"The 39 Steps: A man in London tries to help a counter-espionage Agent. But when the Agent is killed, and the man stands accused, he must go on the run to save himself and stop a spy ring which is trying to steal top secret information.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "r35Ztc4NsVuW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r35Ztc4NsVuW",
    "outputId": "261cee03-74c9-43b1-811f-67b58e829bf6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classify the main genre of the given movie description based on the following genres (Respond with only the genre): “Action”, “Adventure”, “Comedy”, “Crime”, “Documentary”, “Drama”, “Fantasy”, “Horror”, “Romance”, “Sci-Fi”.\n",
      "Breakfast at Tiffany's: A young New York socialite becomes interested in a young man who has moved into her apartment building, but her past threatens to get in the way.\n",
      "Classify the main genre of the given movie description based on the following genres (Respond with only the genre): “Action”, “Adventure”, “Comedy”, “Crime”, “Documentary”, “Drama”, “Fantasy”, “Horror”, “Romance”, “Sci-Fi”.\n",
      "Giant: Sprawling epic covering the life of a Texas cattle rancher and his family and associates.\n",
      "Classify the main genre of the given movie description based on the following genres (Respond with only the genre): “Action”, “Adventure”, “Comedy”, “Crime”, “Documentary”, “Drama”, “Fantasy”, “Horror”, “Romance”, “Sci-Fi”.\n",
      "From Here to Eternity: In Hawaii in 1941, a private is cruelly punished for not boxing on his unit's team, while his captain's wife and second-in-command are falling in love.\n",
      "Classify the main genre of the given movie description based on the following genres (Respond with only the genre): “Action”, “Adventure”, “Comedy”, “Crime”, “Documentary”, “Drama”, “Fantasy”, “Horror”, “Romance”, “Sci-Fi”.\n",
      "Lifeboat: Several survivors of a torpedoed merchant ship in World War II find themselves in the same lifeboat with one of the crew members of the U-boat that sank their ship.\n",
      "Classify the main genre of the given movie description based on the following genres (Respond with only the genre): “Action”, “Adventure”, “Comedy”, “Crime”, “Documentary”, “Drama”, “Fantasy”, “Horror”, “Romance”, “Sci-Fi”.\n",
      "The 39 Steps: A man in London tries to help a counter-espionage Agent. But when the Agent is killed, and the man stands accused, he must go on the run to save himself and stop a spy ring which is trying to steal top secret information.\n"
     ]
    }
   ],
   "source": [
    "prompts = [f\"Classify the main genre of the given movie description based on the following genres (Respond with only the genre): “Action”, “Adventure”, “Comedy”, “Crime”, “Documentary”, “Drama”, “Fantasy”, “Horror”, “Romance”, “Sci-Fi”.\\n{movie}\" for movie in movies]\n",
    "\n",
    "# Log the prompt\n",
    "for prompt in prompts:\n",
    "    print(prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OyGuHllZllct",
   "metadata": {
    "id": "OyGuHllZllct"
   },
   "source": [
    "## Perform batch inference with Curator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c345aa-b6a7-4770-8368-b290e9e799dc",
   "metadata": {
    "id": "64c345aa-b6a7-4770-8368-b290e9e799dc"
   },
   "source": [
    "\n",
    "\n",
    "Now that everything is set, we can execute the inference job. With Curator it is extremely simple, we just need to pass the prompts to the LLM object, and log the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "qqIgWWCn4MIJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "19e4418a0edd484487ab3ce2c2ad28d1",
      "26710d3ecfa4406faf1c4164cf50a4fb",
      "6e163498af57412790eb498f7abd9765",
      "50786dbdef5644a6bbcea4744c7ba45a",
      "264e77364c274ce6b401a45cf0492044",
      "de13df6edf044023901993f113084f8d",
      "937f45453fbf4d8884e29e54ed30b324",
      "a6e3ab9f5591492f8e14920673dc5b27",
      "42e1a96add5b4bc3a9bd0650a42c8212",
      "6098b41bf78240cdab475713c6bdad7a",
      "c2b1d5e01f1b453d834c3eb2ada8c101",
      "bec77dccd0d14485a760137d4bdc1aef",
      "b8cbf8e283034f7e8ac9a22811ef7344",
      "b4f5c41c72634e93913a9e6abd060b5a",
      "1a592861545e46369d21acda969a660a",
      "a1e77f67facd4d1493f45d74f34aea70",
      "92f1fbc1424c46db81559fe41711c364",
      "3b89e61ef99b4d6082fb54797b065228",
      "58724ca6ef814d82be0f9ec0a2b42c3d",
      "23eb24c8f9e844b2ba01defa0aa5dd30",
      "a2edec59a12d4a70a95852c76b4db3a5",
      "d5269d5e84e542a88909642e3576bed7",
      "24499253917d4b10b6835a5c0aa95f55",
      "b611d9e156954ea186c5f1df4f4356b8"
     ]
    },
    "id": "qqIgWWCn4MIJ",
    "outputId": "2469d86f-6825-4f23-a13d-4c8d36498838"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/17/25 10:50:47] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Running OpenAIBatchRequestProcessor completions with     <a href=\"file:///Users/kevin/.pyenv/versions/3.10.8/lib/python3.10/site-packages/bespokelabs/curator/request_processor/base_request_processor.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base_request_processor.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/kevin/.pyenv/versions/3.10.8/lib/python3.10/site-packages/bespokelabs/curator/request_processor/base_request_processor.py#131\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">131</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         model: klusterai/Meta-Llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.1</span>-8B-Instruct-Turbo        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/17/25 10:50:47]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Running OpenAIBatchRequestProcessor completions with     \u001b]8;id=547340;file:///Users/kevin/.pyenv/versions/3.10.8/lib/python3.10/site-packages/bespokelabs/curator/request_processor/base_request_processor.py\u001b\\\u001b[2mbase_request_processor.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=57191;file:///Users/kevin/.pyenv/versions/3.10.8/lib/python3.10/site-packages/bespokelabs/curator/request_processor/base_request_processor.py#131\u001b\\\u001b[2m131\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         model: klusterai/Meta-Llama-\u001b[1;36m3.1\u001b[0m-8B-Instruct-Turbo        \u001b[2m                             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Using cached requests. If you want to regenerate the     <a href=\"file:///Users/kevin/.pyenv/versions/3.10.8/lib/python3.10/site-packages/bespokelabs/curator/request_processor/base_request_processor.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base_request_processor.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/kevin/.pyenv/versions/3.10.8/lib/python3.10/site-packages/bespokelabs/curator/request_processor/base_request_processor.py#212\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">212</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         dataset, disable or delete the cache.                    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>          See                                                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://docs.bespokelabs.ai/bespoke-curator/tutorials/au</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">tomatic-recovery-and-caching#disable-caching</span> for more    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         information.                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Using cached requests. If you want to regenerate the     \u001b]8;id=996264;file:///Users/kevin/.pyenv/versions/3.10.8/lib/python3.10/site-packages/bespokelabs/curator/request_processor/base_request_processor.py\u001b\\\u001b[2mbase_request_processor.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=124424;file:///Users/kevin/.pyenv/versions/3.10.8/lib/python3.10/site-packages/bespokelabs/curator/request_processor/base_request_processor.py#212\u001b\\\u001b[2m212\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         dataset, disable or delete the cache.                    \u001b[2m                             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m          See                                                     \u001b[2m                             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;94mhttps://docs.bespokelabs.ai/bespoke-curator/tutorials/au\u001b[0m \u001b[2m                             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;94mtomatic-recovery-and-caching#disable-caching\u001b[0m for more    \u001b[2m                             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         information.                                             \u001b[2m                             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loaded existing tracker from                       <a href=\"file:///Users/kevin/.pyenv/versions/3.10.8/lib/python3.10/site-packages/bespokelabs/curator/request_processor/batch/base_batch_request_processor.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base_batch_request_processor.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/kevin/.pyenv/versions/3.10.8/lib/python3.10/site-packages/bespokelabs/curator/request_processor/batch/base_batch_request_processor.py#301\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">301</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #800080; text-decoration-color: #800080\">/Users/kevin/.cache/curator/a879796c1be047b5/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">batch</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                                   </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">_objects.jsonl</span>                                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loaded existing tracker from                       \u001b]8;id=728476;file:///Users/kevin/.pyenv/versions/3.10.8/lib/python3.10/site-packages/bespokelabs/curator/request_processor/batch/base_batch_request_processor.py\u001b\\\u001b[2mbase_batch_request_processor.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=601968;file:///Users/kevin/.pyenv/versions/3.10.8/lib/python3.10/site-packages/bespokelabs/curator/request_processor/batch/base_batch_request_processor.py#301\u001b\\\u001b[2m301\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[35m/Users/kevin/.cache/curator/a879796c1be047b5/\u001b[0m\u001b[95mbatch\u001b[0m \u001b[2m                                   \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[95m_objects.jsonl\u001b[0m                                     \u001b[2m                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a171938861c24874bb6650a1478e4a82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">•</span> Time Elapsed <span style=\"color: #808000; text-decoration-color: #808000\">0:00:04</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">•</span> Time Remaining <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[1;37m•\u001b[0m Time Elapsed \u001b[33m0:00:04\u001b[0m \u001b[1;37m•\u001b[0m Time Remaining \u001b[36m0:00:00\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">Curator Viewer:</span> <span style=\"color: #808000; text-decoration-color: #808000\">Disabled</span>                                                            \n",
       "Set <span style=\"color: #808000; text-decoration-color: #808000\">HOSTED_CURATOR_VIEWER=</span><span style=\"color: #008080; text-decoration-color: #008080\">1</span> to view your data live at <span style=\"color: #000080; text-decoration-color: #000080\">https://curator.bespokelabs.ai</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">Batches:</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Total:</span> <span style=\"color: #000080; text-decoration-color: #000080\">1</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">•</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Submitted:</span> <span style=\"color: #808000; text-decoration-color: #808000\">0⋯</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">•</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Downloaded:</span> <span style=\"color: #008000; text-decoration-color: #008000\">1✓</span>                                  \n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">Requests:</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Total:</span> <span style=\"color: #000080; text-decoration-color: #000080\">5</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">•</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Submitted:</span> <span style=\"color: #808000; text-decoration-color: #808000\">0⋯</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">•</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Succeeded:</span> <span style=\"color: #008000; text-decoration-color: #008000\">5✓</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">•</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Failed:</span> <span style=\"color: #800000; text-decoration-color: #800000\">0✗</span>                     \n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">Tokens:</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Avg Input:</span> <span style=\"color: #000080; text-decoration-color: #000080\">133</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">•</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Avg Output:</span> <span style=\"color: #000080; text-decoration-color: #000080\">3</span>                                              \n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">Cost:</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Current:</span> <span style=\"color: #800080; text-decoration-color: #800080\">$0.000</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">•</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Projected:</span> <span style=\"color: #800080; text-decoration-color: #800080\">$0.000</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">•</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Rate:</span> <span style=\"color: #800080; text-decoration-color: #800080\">$0.000/request</span>                    \n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">Model:</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Name:</span> <span style=\"color: #000080; text-decoration-color: #000080\">klusterai/Meta-Llama-3.1-8B-Instruct-Turbo</span>                             \n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">Model Pricing:</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Per 1M tokens:</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Input:</span> <span style=\"color: #800000; text-decoration-color: #800000\">$0.050</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">•</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Output:</span> <span style=\"color: #800000; text-decoration-color: #800000\">$0.050</span>                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;37mCurator Viewer:\u001b[0m \u001b[33mDisabled\u001b[0m                                                            \n",
       "Set \u001b[33mHOSTED_CURATOR_VIEWER=\u001b[0m\u001b[36m1\u001b[0m to view your data live at \u001b[34mhttps://curator.bespokelabs.ai\u001b[0m\n",
       "\u001b[1;37mBatches:\u001b[0m \u001b[37mTotal:\u001b[0m \u001b[34m1\u001b[0m \u001b[37m•\u001b[0m \u001b[37mSubmitted:\u001b[0m \u001b[33m0⋯\u001b[0m \u001b[37m•\u001b[0m \u001b[37mDownloaded:\u001b[0m \u001b[32m1✓\u001b[0m                                  \n",
       "\u001b[1;37mRequests:\u001b[0m \u001b[37mTotal:\u001b[0m \u001b[34m5\u001b[0m \u001b[37m•\u001b[0m \u001b[37mSubmitted:\u001b[0m \u001b[33m0⋯\u001b[0m \u001b[37m•\u001b[0m \u001b[37mSucceeded:\u001b[0m \u001b[32m5✓\u001b[0m \u001b[37m•\u001b[0m \u001b[37mFailed:\u001b[0m \u001b[31m0✗\u001b[0m                     \n",
       "\u001b[1;37mTokens:\u001b[0m \u001b[37mAvg Input:\u001b[0m \u001b[34m133\u001b[0m \u001b[37m•\u001b[0m \u001b[37mAvg Output:\u001b[0m \u001b[34m3\u001b[0m                                              \n",
       "\u001b[1;37mCost:\u001b[0m \u001b[37mCurrent:\u001b[0m \u001b[35m$0.000\u001b[0m \u001b[37m•\u001b[0m \u001b[37mProjected:\u001b[0m \u001b[35m$0.000\u001b[0m \u001b[37m•\u001b[0m \u001b[37mRate:\u001b[0m \u001b[35m$0.000/request\u001b[0m                    \n",
       "\u001b[1;37mModel:\u001b[0m \u001b[37mName:\u001b[0m \u001b[34mklusterai/Meta-Llama-3.1-8B-Instruct-Turbo\u001b[0m                             \n",
       "\u001b[1;37mModel Pricing:\u001b[0m \u001b[37mPer 1M tokens:\u001b[0m \u001b[37mInput:\u001b[0m \u001b[31m$0.050\u001b[0m \u001b[37m•\u001b[0m \u001b[37mOutput:\u001b[0m \u001b[31m$0.050\u001b[0m                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                         Final Curator Statistics                          </span>\n",
       "╭────────────────────────────┬────────────────────────────────────────────╮\n",
       "│<span style=\"font-weight: bold\"> Section/Metric             </span>│<span style=\"font-weight: bold\"> Value                                      </span>│\n",
       "├────────────────────────────┼────────────────────────────────────────────┤\n",
       "│<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Model                      </span>│<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">                                            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Model                      </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> </span><span style=\"color: #000080; text-decoration-color: #000080\">klusterai/Meta-Llama-3.1-8B-Instruct-Turbo</span><span style=\"color: #808000; text-decoration-color: #808000\"> </span>│\n",
       "│<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Batches                    </span>│<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">                                            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Total Batches              </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> 1                                          </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Submitted                  </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> 0                                          </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Downloaded                 </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> </span><span style=\"color: #008000; text-decoration-color: #008000\">1</span><span style=\"color: #808000; text-decoration-color: #808000\">                                          </span>│\n",
       "│<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Requests                   </span>│<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">                                            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Total Requests             </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> 5                                          </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Successful                 </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> </span><span style=\"color: #008000; text-decoration-color: #008000\">5</span><span style=\"color: #808000; text-decoration-color: #808000\">                                          </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Failed                     </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> </span><span style=\"color: #800000; text-decoration-color: #800000\">0</span><span style=\"color: #808000; text-decoration-color: #808000\">                                          </span>│\n",
       "│<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Tokens                     </span>│<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">                                            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Total Tokens Used          </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> 0                                          </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Total Input Tokens         </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> 664                                        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Total Output Tokens        </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> 14                                         </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Average Tokens per Request </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> 0                                          </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Average Input Tokens       </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> 132                                        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Average Output Tokens      </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> 2                                          </span>│\n",
       "│<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Costs                      </span>│<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">                                            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Total Cost                 </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> </span><span style=\"color: #800000; text-decoration-color: #800000\">$0.000</span><span style=\"color: #808000; text-decoration-color: #808000\">                                     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Projected Remaining Cost   </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> </span><span style=\"color: #800000; text-decoration-color: #800000\">$0.000</span><span style=\"color: #808000; text-decoration-color: #808000\">                                     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Projected Total Cost       </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> </span><span style=\"color: #800000; text-decoration-color: #800000\">$0.000</span><span style=\"color: #808000; text-decoration-color: #808000\">                                     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Average Cost per Request   </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> </span><span style=\"color: #800000; text-decoration-color: #800000\">$0.000</span><span style=\"color: #808000; text-decoration-color: #808000\">                                     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Input Cost per 1M Tokens   </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> </span><span style=\"color: #800000; text-decoration-color: #800000\">$0.050</span><span style=\"color: #808000; text-decoration-color: #808000\">                                     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Output Cost per 1M Tokens  </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> </span><span style=\"color: #800000; text-decoration-color: #800000\">$0.050</span><span style=\"color: #808000; text-decoration-color: #808000\">                                     </span>│\n",
       "│<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Performance                </span>│<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">                                            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Total Time                 </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> 53.08s                                     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Average Time per Request   </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> 10.62s                                     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Requests per Minute        </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> 5.7                                        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Input Tokens per Minute    </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> 750.6                                      </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Output Tokens per Minute   </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> 15.8                                       </span>│\n",
       "╰────────────────────────────┴────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                         Final Curator Statistics                          \u001b[0m\n",
       "╭────────────────────────────┬────────────────────────────────────────────╮\n",
       "│\u001b[1m \u001b[0m\u001b[1mSection/Metric            \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1mValue                                     \u001b[0m\u001b[1m \u001b[0m│\n",
       "├────────────────────────────┼────────────────────────────────────────────┤\n",
       "│\u001b[1;35m \u001b[0m\u001b[1;35mModel                     \u001b[0m\u001b[1;35m \u001b[0m│\u001b[1;35m \u001b[0m\u001b[1;35m                                          \u001b[0m\u001b[1;35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mModel                     \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[34mklusterai/Meta-Llama-3.1-8B-Instruct-Turbo\u001b[0m\u001b[33m \u001b[0m│\n",
       "│\u001b[1;35m \u001b[0m\u001b[1;35mBatches                   \u001b[0m\u001b[1;35m \u001b[0m│\u001b[1;35m \u001b[0m\u001b[1;35m                                          \u001b[0m\u001b[1;35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mTotal Batches             \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m1                                         \u001b[0m\u001b[33m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mSubmitted                 \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m0\u001b[0m\u001b[33m                                         \u001b[0m\u001b[33m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mDownloaded                \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[32m1\u001b[0m\u001b[33m                                         \u001b[0m\u001b[33m \u001b[0m│\n",
       "│\u001b[1;35m \u001b[0m\u001b[1;35mRequests                  \u001b[0m\u001b[1;35m \u001b[0m│\u001b[1;35m \u001b[0m\u001b[1;35m                                          \u001b[0m\u001b[1;35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mTotal Requests            \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m5                                         \u001b[0m\u001b[33m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mSuccessful                \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[32m5\u001b[0m\u001b[33m                                         \u001b[0m\u001b[33m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mFailed                    \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[31m0\u001b[0m\u001b[33m                                         \u001b[0m\u001b[33m \u001b[0m│\n",
       "│\u001b[1;35m \u001b[0m\u001b[1;35mTokens                    \u001b[0m\u001b[1;35m \u001b[0m│\u001b[1;35m \u001b[0m\u001b[1;35m                                          \u001b[0m\u001b[1;35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mTotal Tokens Used         \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m0                                         \u001b[0m\u001b[33m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mTotal Input Tokens        \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m664                                       \u001b[0m\u001b[33m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mTotal Output Tokens       \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m14                                        \u001b[0m\u001b[33m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mAverage Tokens per Request\u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m0                                         \u001b[0m\u001b[33m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mAverage Input Tokens      \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m132                                       \u001b[0m\u001b[33m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mAverage Output Tokens     \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m2                                         \u001b[0m\u001b[33m \u001b[0m│\n",
       "│\u001b[1;35m \u001b[0m\u001b[1;35mCosts                     \u001b[0m\u001b[1;35m \u001b[0m│\u001b[1;35m \u001b[0m\u001b[1;35m                                          \u001b[0m\u001b[1;35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mTotal Cost                \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[31m$0.000\u001b[0m\u001b[33m                                    \u001b[0m\u001b[33m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mProjected Remaining Cost  \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[31m$0.000\u001b[0m\u001b[33m                                    \u001b[0m\u001b[33m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mProjected Total Cost      \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[31m$0.000\u001b[0m\u001b[33m                                    \u001b[0m\u001b[33m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mAverage Cost per Request  \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[31m$0.000\u001b[0m\u001b[33m                                    \u001b[0m\u001b[33m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mInput Cost per 1M Tokens  \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[31m$0.050\u001b[0m\u001b[33m                                    \u001b[0m\u001b[33m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mOutput Cost per 1M Tokens \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[31m$0.050\u001b[0m\u001b[33m                                    \u001b[0m\u001b[33m \u001b[0m│\n",
       "│\u001b[1;35m \u001b[0m\u001b[1;35mPerformance               \u001b[0m\u001b[1;35m \u001b[0m│\u001b[1;35m \u001b[0m\u001b[1;35m                                          \u001b[0m\u001b[1;35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mTotal Time                \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m53.08s                                    \u001b[0m\u001b[33m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mAverage Time per Request  \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m10.62s                                    \u001b[0m\u001b[33m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mRequests per Minute       \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m5.7                                       \u001b[0m\u001b[33m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mInput Tokens per Minute   \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m750.6                                     \u001b[0m\u001b[33m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mOutput Tokens per Minute  \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m15.8                                      \u001b[0m\u001b[33m \u001b[0m│\n",
       "╰────────────────────────────┴────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/17/25 10:50:52] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Read <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> responses.                                        <a href=\"file:///Users/kevin/.pyenv/versions/3.10.8/lib/python3.10/site-packages/bespokelabs/curator/request_processor/base_request_processor.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base_request_processor.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/kevin/.pyenv/versions/3.10.8/lib/python3.10/site-packages/bespokelabs/curator/request_processor/base_request_processor.py#442\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">442</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/17/25 10:50:52]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Read \u001b[1;36m5\u001b[0m responses.                                        \u001b]8;id=670651;file:///Users/kevin/.pyenv/versions/3.10.8/lib/python3.10/site-packages/bespokelabs/curator/request_processor/base_request_processor.py\u001b\\\u001b[2mbase_request_processor.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=12340;file:///Users/kevin/.pyenv/versions/3.10.8/lib/python3.10/site-packages/bespokelabs/curator/request_processor/base_request_processor.py#442\u001b\\\u001b[2m442\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Finalizing writer                                        <a href=\"file:///Users/kevin/.pyenv/versions/3.10.8/lib/python3.10/site-packages/bespokelabs/curator/request_processor/base_request_processor.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base_request_processor.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/kevin/.pyenv/versions/3.10.8/lib/python3.10/site-packages/bespokelabs/curator/request_processor/base_request_processor.py#451\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">451</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Finalizing writer                                        \u001b]8;id=641362;file:///Users/kevin/.pyenv/versions/3.10.8/lib/python3.10/site-packages/bespokelabs/curator/request_processor/base_request_processor.py\u001b\\\u001b[2mbase_request_processor.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=870512;file:///Users/kevin/.pyenv/versions/3.10.8/lib/python3.10/site-packages/bespokelabs/curator/request_processor/base_request_processor.py#451\u001b\\\u001b[2m451\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Creating a file with all failed requests                 <a href=\"file:///Users/kevin/.pyenv/versions/3.10.8/lib/python3.10/site-packages/bespokelabs/curator/request_processor/base_request_processor.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base_request_processor.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/kevin/.pyenv/versions/3.10.8/lib/python3.10/site-packages/bespokelabs/curator/request_processor/base_request_processor.py#460\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">460</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Creating a file with all failed requests                 \u001b]8;id=414543;file:///Users/kevin/.pyenv/versions/3.10.8/lib/python3.10/site-packages/bespokelabs/curator/request_processor/base_request_processor.py\u001b\\\u001b[2mbase_request_processor.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=924566;file:///Users/kevin/.pyenv/versions/3.10.8/lib/python3.10/site-packages/bespokelabs/curator/request_processor/base_request_processor.py#460\u001b\\\u001b[2m460\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Created file with failed requests at                     <a href=\"file:///Users/kevin/.pyenv/versions/3.10.8/lib/python3.10/site-packages/bespokelabs/curator/request_processor/base_request_processor.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base_request_processor.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/kevin/.pyenv/versions/3.10.8/lib/python3.10/site-packages/bespokelabs/curator/request_processor/base_request_processor.py#488\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">488</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #800080; text-decoration-color: #800080\">/Users/kevin/.cache/curator/a879796c1be047b5/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">failed_requ</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">ests.jsonl</span>                                               <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Created file with failed requests at                     \u001b]8;id=790656;file:///Users/kevin/.pyenv/versions/3.10.8/lib/python3.10/site-packages/bespokelabs/curator/request_processor/base_request_processor.py\u001b\\\u001b[2mbase_request_processor.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=844863;file:///Users/kevin/.pyenv/versions/3.10.8/lib/python3.10/site-packages/bespokelabs/curator/request_processor/base_request_processor.py#488\u001b\\\u001b[2m488\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[35m/Users/kevin/.cache/curator/a879796c1be047b5/\u001b[0m\u001b[95mfailed_requ\u001b[0m \u001b[2m                             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[95mests.jsonl\u001b[0m                                               \u001b[2m                             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "responses = llm(prompts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5650dde",
   "metadata": {},
   "source": [
    "Lastly, let's print the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "xKhW-uXy4X32",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xKhW-uXy4X32",
    "outputId": "37af6cf3-044c-451f-ef9f-a61d3bfb0d56"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Drama', 'Drama', 'Drama', 'Drama', 'Action']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses['response']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e0e816-6558-4ff2-bab2-f85cff00bfc8",
   "metadata": {
    "id": "70e0e816-6558-4ff2-bab2-f85cff00bfc8"
   },
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d195dd1-1293-4407-b6ad-cab7e77b14c0",
   "metadata": {
    "id": "7d195dd1-1293-4407-b6ad-cab7e77b14c0"
   },
   "source": [
    "This tutorial used the chat completion endpoint and Bespoke Curator to perform a simple text classification task with batch inference. This particular example clasified a series of movies based on their description.\n",
    "\n",
    "Using Curator, submitting a batch job is extremely simple. It handles all the steps of creating the file, uploading it, submitting the batch job, monitoring the job, and retrieving results. Moreover, kluster.ai is natively supported, making things even easier!\n",
    "\n",
    "\n",
    "Kluster.ai's batch API empowers you to scale your workflows seamlessly, making it an invaluable tool for processing extensive datasets. As next steps, feel free to create your own dataset, or expand on top of this existing example. Good luck!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
