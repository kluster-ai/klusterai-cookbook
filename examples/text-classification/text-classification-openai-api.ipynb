{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be189fde-4e5b-4f80-bae1-ded86a5075a7",
   "metadata": {
    "id": "be189fde-4e5b-4f80-bae1-ded86a5075a7"
   },
   "source": [
    "# Text classification with kluster.ai API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17a77d9",
   "metadata": {
    "id": "b17a77d9"
   },
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/kluster-ai/klusterai-cookbook/blob/main/examples/text-classification/text-classification-openai-api.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1d06ea-79c1-4f28-b312-0e5aabe18ff3",
   "metadata": {
    "id": "6d1d06ea-79c1-4f28-b312-0e5aabe18ff3"
   },
   "source": [
    "Text classification is assigning a class/label to a given text, and it is a common go-to example to demonstrate how helpful an AI model can be.\n",
    "\n",
    "This tutorial runs through a notebook where you'll learn how to use the <a href=\"https://kluster.ai/\" target=\"_blank\">kluster.ai</a> batch API to classify a dataset based on a predefined set of categories.\n",
    "\n",
    "The example uses an extract from the IMDB top 1000 movies dataset and categorizes them into \"Action,\" \"Adventure,\" \"Comedy,\" \"Crime,\" \"Documentary,\" \"Drama,\" \"Fantasy,\" \"Horror,\" \"Romance,\" or \"Sci-Fi.\"\n",
    "\n",
    "You can adapt this example by using your data and categories relevant to your use case. With this approach, you can effortlessly process datasets of any scale, big or small, and obtain categorized results powered by a state-of-the-art language model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766af796",
   "metadata": {
    "id": "766af796"
   },
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ac421b",
   "metadata": {
    "id": "05ac421b"
   },
   "source": [
    "Before getting started, ensure you have the following:\n",
    "\n",
    "- **A kluster.ai account** - sign up on the <a href=\"https://platform.kluster.ai/signup\" target=\"_blank\">kluster.ai platform</a> if you don't have one\n",
    "- **A kluster.ai API key** - after signing in, go to the <a href=\"https://platform.kluster.ai/apikeys\" target=\"_blank\">**API Keys**</a> section and create a new key. For detailed instructions, check out the <a href=\"/get-started/get-api-key/\" target=\"_blank\">Get an API key</a> guide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addf05c2",
   "metadata": {
    "id": "addf05c2"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4185a24a",
   "metadata": {
    "id": "4185a24a"
   },
   "source": [
    "In this notebook, we'll use Python's `getpass` module to safely input the key. After execution, please provide your unique kluster.ai API key (ensure no spaces)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4911e5eb-7463-4a6b-8a99-9313cecd9d4d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4911e5eb-7463-4a6b-8a99-9313cecd9d4d",
    "outputId": "9a3b7b57-5b91-4f78-ec78-647cfbbf577e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your kluster.ai API key: ··········\n"
     ]
    }
   ],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "api_key = getpass(\"Enter your kluster.ai API key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8df6b97",
   "metadata": {
    "id": "f8df6b97"
   },
   "source": [
    "Next, ensure you've installed OpenAI Python library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcc3d475-8f49-4fc4-9a5e-c6eb6866d2b5",
   "metadata": {
    "id": "bcc3d475-8f49-4fc4-9a5e-c6eb6866d2b5"
   },
   "outputs": [],
   "source": [
    "pip install -q openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406c94a2",
   "metadata": {
    "id": "406c94a2"
   },
   "source": [
    "With the OpenAI Python library installed, we import the necessary dependencies for the tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b89a4feb-37a9-430d-a742-cd58495b4eaf",
   "metadata": {
    "id": "b89a4feb-37a9-430d-a742-cd58495b4eaf"
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "from IPython.display import clear_output, display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabf941b",
   "metadata": {
    "id": "eabf941b"
   },
   "source": [
    "And then, initialize the `client` by pointing it to the kluster.ai endpoint, and passing your API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "zG9y_WO5rYaj",
   "metadata": {
    "id": "zG9y_WO5rYaj"
   },
   "outputs": [],
   "source": [
    "# Set up the client\n",
    "client = OpenAI(\n",
    "    base_url=\"https://api.kluster.ai/v1\",\n",
    "    api_key=api_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "udPtLfTaisSw",
   "metadata": {
    "id": "udPtLfTaisSw"
   },
   "source": [
    "## Get the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QjCVfg65jKz6",
   "metadata": {
    "id": "QjCVfg65jKz6"
   },
   "source": [
    "Now that you've initialized an OpenAI-compatible client pointing to kluster.ai, we can talk about the data.\n",
    "\n",
    "This notebook includes a preloaded sample dataset derived from the Top 1000 IMDb Movies dataset. It contains movie descriptions ready for classification. No additional setup is needed. Simply proceed to the next steps to begin working with this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07018f92-9a01-47d5-916a-12cd03dfa3a0",
   "metadata": {
    "id": "07018f92-9a01-47d5-916a-12cd03dfa3a0"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"text\": [\n",
    "        \"Breakfast at Tiffany's: A young New York socialite becomes interested in a young man who has moved into her apartment building, but her past threatens to get in the way.\",\n",
    "        \"Giant: Sprawling epic covering the life of a Texas cattle rancher and his family and associates.\",\n",
    "        \"From Here to Eternity: In Hawaii in 1941, a private is cruelly punished for not boxing on his unit's team, while his captain's wife and second-in-command are falling in love.\",\n",
    "        \"Lifeboat: Several survivors of a torpedoed merchant ship in World War II find themselves in the same lifeboat with one of the crew members of the U-boat that sank their ship.\",\n",
    "        \"The 39 Steps: A man in London tries to help a counter-espionage Agent. But when the Agent is killed, and the man stands accused, he must go on the run to save himself and stop a spy ring which is trying to steal top secret information.\"\n",
    "    ]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OyGuHllZllct",
   "metadata": {
    "id": "OyGuHllZllct"
   },
   "source": [
    "## Perform batch inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c345aa-b6a7-4770-8368-b290e9e799dc",
   "metadata": {
    "id": "64c345aa-b6a7-4770-8368-b290e9e799dc"
   },
   "source": [
    "To execute the batch inference job, we'll take the following steps:\n",
    "\n",
    "1. **Create the batch job file** - we'll generate a JSON lines file with the desired requests to be processed by the model\n",
    "2. **Upload the batch job file** - once it is ready, we'll upload it to the <a href=\"https://platform.kluster.ai/signup\" target=\"_blank\">kluster.ai platform</a> using the API, where it will be processed. We'll receive a unique ID associated with our file\n",
    "3. **Start the batch job** - after the file is uploaded, we'll initiate the job to process the uploaded data, using the file ID obtained before\n",
    "4. **Monitor job progress** - (optional) track the status of the batch job to ensure it has been successfully completed\n",
    "5. **Retrieve results** - once the job has completed execution, we can access and process the resultant data\n",
    "\n",
    "This notebook is prepared for you to follow along. Run the cells below to watch it all come together."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Ew-R24Ltp5EW",
   "metadata": {
    "id": "Ew-R24Ltp5EW"
   },
   "source": [
    "### Create the batch job file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qS4JXT52wGJ-",
   "metadata": {
    "id": "qS4JXT52wGJ-"
   },
   "source": [
    "This example selects the `deepseek-ai/DeepSeek-V3` model. If you'd like to use a different model, feel free to change it by modifying the `model` field. In this notebook, you can also comment DeepSeek V3, and uncomment whatever model you want to try out.\n",
    "\n",
    "Please refer to the <a href=\"/get-started/start-building/batch/#supported-models\" target=\"_blank\">Supported models</a> section for a list of the models we support.\n",
    "\n",
    "The following snippets prepare the JSONL file, where each line represents a different request. Note that each separate batch request can have its own model. Also, we are using a temperature of `0.5` but feel free to change it and play around with the different outcomes (but we are only asking to respond with a single word, the genre)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fVtwyqZ_nEq7",
   "metadata": {
    "id": "fVtwyqZ_nEq7"
   },
   "outputs": [],
   "source": [
    "# Prompt\n",
    "SYSTEM_PROMPT = '''\n",
    "    Classify the main genre of the given movie description based on the following genres (Respond with only the genre):\n",
    "    “Action”, “Adventure”, “Comedy”, “Crime”, “Documentary”, “Drama”, “Fantasy”, “Horror”, “Romance”, “Sci-Fi”.\n",
    "    '''\n",
    "\n",
    "# Models\n",
    "#model=\"deepseek-ai/DeepSeek-R1\"\n",
    "model=\"deepseek-ai/DeepSeek-V3\"\n",
    "#model=\"klusterai/Meta-Llama-3.1-8B-Instruct-Turbo\"\n",
    "#model=\"klusterai/Meta-Llama-3.1-405B-Instruct-Turbo\"\n",
    "#model=\"klusterai/Meta-Llama-3.3-70B-Instruct-Turbo\"\n",
    "#model=\"Qwen/Qwen2.5-VL-7B-Instruct\"\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(\"text_clasification/data\", exist_ok=True)\n",
    "\n",
    "# Create the batch job file with the prompt and content\n",
    "def create_batch_file(df):\n",
    "    batch_list = []\n",
    "    for index, row in df.iterrows():\n",
    "        content = row['text']\n",
    "\n",
    "        request = {\n",
    "            \"custom_id\": f\"movie_classification-{index}\",\n",
    "            \"method\": \"POST\",\n",
    "            \"url\": \"/v1/chat/completions\",\n",
    "            \"body\": {\n",
    "                \"model\": model,\n",
    "                \"temperature\": 0.5,\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "                    {\"role\": \"user\", \"content\": content}\n",
    "                ],\n",
    "            }\n",
    "        }\n",
    "        batch_list.append(request)\n",
    "    return batch_list\n",
    "\n",
    "# Save file\n",
    "def save_batch_file(batch_list):\n",
    "    filename = f\"text_clasification/batch_job_request.jsonl\"\n",
    "    with open(filename, 'w') as file:\n",
    "        for request in batch_list:\n",
    "            file.write(json.dumps(request) + '\\n')\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8bbb40",
   "metadata": {
    "id": "5f8bbb40"
   },
   "source": [
    "Let's run the functions we've defined before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "qNhmrmHdnp7g",
   "metadata": {
    "id": "qNhmrmHdnp7g"
   },
   "outputs": [],
   "source": [
    "batch_list = create_batch_file(df)\n",
    "filename = save_batch_file(batch_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada26fe3-acb9-48dc-b368-b57fc380cdb8",
   "metadata": {
    "id": "ada26fe3-acb9-48dc-b368-b57fc380cdb8"
   },
   "source": [
    "Next, we can preview what that batch job file looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d65f5099-5add-4749-9a85-3c04a9b342bb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d65f5099-5add-4749-9a85-3c04a9b342bb",
    "outputId": "168c1f53-1f52-44ab-c4e5-3820d2614482"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"custom_id\": \"movie_classification-0\", \"method\": \"POST\", \"url\": \"/v1/chat/completions\", \"body\": {\"model\": \"deepseek-ai/DeepSeek-V3\", \"temperature\": 0.5, \"messages\": [{\"role\": \"system\", \"content\": \"\\n    Classify the main genre of the given movie description based on the following genres (Respond with only the genre):\\n    \\u201cAction\\u201d, \\u201cAdventure\\u201d, \\u201cComedy\\u201d, \\u201cCrime\\u201d, \\u201cDocumentary\\u201d, \\u201cDrama\\u201d, \\u201cFantasy\\u201d, \\u201cHorror\\u201d, \\u201cRomance\\u201d, \\u201cSci-Fi\\u201d.\\n    \"}, {\"role\": \"user\", \"content\": \"Breakfast at Tiffany's: A young New York socialite becomes interested in a young man who has moved into her apartment building, but her past threatens to get in the way.\"}]}}\n"
     ]
    }
   ],
   "source": [
    "!head -n 1 text_clasification/batch_job_request.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xArKu7-sqSiR",
   "metadata": {
    "id": "xArKu7-sqSiR"
   },
   "source": [
    "### Upload batch job file to kluster.ai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48b2489-99bc-431b-8cb3-de816550d524",
   "metadata": {
    "id": "e48b2489-99bc-431b-8cb3-de816550d524"
   },
   "source": [
    "Now that we’ve prepared our input file, it’s time to upload it to the kluster.ai platform. To do so, you can use the `files.create` endpoint of the client, where the purpose is set to `batch`. This will return the file ID, which we need to log for the next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "l5eu5UyAnEtk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l5eu5UyAnEtk",
    "outputId": "bcd0915a-5e28-454e-f5c3-7ce1a6b875f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File uploaded successfully. File ID: 67ddb3ef6afe1d706e51b7a6\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'text_clasification/batch_job_request.jsonl'\n",
    "\n",
    "# Upload batch job request file\n",
    "with open(data_dir, 'rb') as file:\n",
    "    upload_response = client.files.create(\n",
    "        file=file,\n",
    "        purpose=\"batch\"\n",
    "    )\n",
    "\n",
    "    # Print job ID\n",
    "    file_id = upload_response.id\n",
    "    print(f\"File uploaded successfully. File ID: {file_id}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6438be35-1e73-4c34-9249-2dd16d102253",
   "metadata": {
    "id": "6438be35-1e73-4c34-9249-2dd16d102253"
   },
   "source": [
    "### Start the batch job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251a0b89-71a9-40d7-bf14-51be935afe10",
   "metadata": {
    "id": "251a0b89-71a9-40d7-bf14-51be935afe10"
   },
   "source": [
    "Once the file has been successfully uploaded, we're ready to start (create) the batch job by providing the file ID we got in the previous step. To do so, we use the `batches.create` method, for which we need to set the endpoint to `/v1/chat/completions`. This will return the batch job details, with the ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71a24704-7190-4e24-898f-c4eff062439a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "71a24704-7190-4e24-898f-c4eff062439a",
    "outputId": "5ae036d1-c686-4a12-ab38-1ba6e34729b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch job created:\n",
      "{\n",
      "  \"id\": \"67ddb3f151ba53f099cdb3f9\",\n",
      "  \"completion_window\": \"24h\",\n",
      "  \"created_at\": 1742582769,\n",
      "  \"endpoint\": \"/v1/chat/completions\",\n",
      "  \"input_file_id\": \"67ddb3ef6afe1d706e51b7a6\",\n",
      "  \"object\": \"batch\",\n",
      "  \"status\": \"pre_schedule\",\n",
      "  \"cancelled_at\": null,\n",
      "  \"cancelling_at\": null,\n",
      "  \"completed_at\": null,\n",
      "  \"error_file_id\": null,\n",
      "  \"errors\": [],\n",
      "  \"expired_at\": null,\n",
      "  \"expires_at\": 1742669169,\n",
      "  \"failed_at\": null,\n",
      "  \"finalizing_at\": null,\n",
      "  \"in_progress_at\": null,\n",
      "  \"metadata\": {},\n",
      "  \"output_file_id\": null,\n",
      "  \"request_counts\": {\n",
      "    \"completed\": 0,\n",
      "    \"failed\": 0,\n",
      "    \"total\": 0\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Create batch job with completions endpoint\n",
    "batch_job = client.batches.create(\n",
    "    input_file_id=file_id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\"\n",
    ")\n",
    "\n",
    "print(\"\\nBatch job created:\")\n",
    "batch_dict = batch_job.model_dump()\n",
    "print(json.dumps(batch_dict, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e-ujphILqepu",
   "metadata": {
    "id": "e-ujphILqepu"
   },
   "source": [
    "### Check job progress"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iFrDrriQqizC",
   "metadata": {
    "id": "iFrDrriQqizC"
   },
   "source": [
    "Now that your batch job has been created, you can track its progress.\n",
    "\n",
    "To monitor the job's progress, we can use the `batches.retrieve` method and pass the batch job ID. The response contains an `status` field that tells us if it is completed or not, and the subsequent status of each job separately.\n",
    "\n",
    "The following snippet checks the status every 10 seconds until the entire batch is completed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "SuH0CfoqjP3d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "SuH0CfoqjP3d",
    "outputId": "ff0fce21-23d1-46bb-97e1-330f0acee83c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Job completed!'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_completed = False\n",
    "\n",
    "# Loop to check status every 10 seconds\n",
    "while not all_completed:\n",
    "    all_completed = True\n",
    "    output_lines = []\n",
    "\n",
    "    updated_job = client.batches.retrieve(batch_job.id)\n",
    "\n",
    "    if updated_job.status != \"completed\":\n",
    "        all_completed = False\n",
    "        completed = updated_job.request_counts.completed\n",
    "        total = updated_job.request_counts.total\n",
    "        output_lines.append(f\"Job status: {updated_job.status} - Progress: {completed}/{total}\")\n",
    "    else:\n",
    "        output_lines.append(f\"Job completed!\")\n",
    "\n",
    "    # Clear the output and display updated status\n",
    "    clear_output(wait=True)\n",
    "    for line in output_lines:\n",
    "        display(line)\n",
    "\n",
    "    if not all_completed:\n",
    "        time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TkkhIG9HU0D9",
   "metadata": {
    "id": "TkkhIG9HU0D9"
   },
   "source": [
    "## Get the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c1f6ac-8d60-4158-9036-de79fa274983",
   "metadata": {
    "id": "12c1f6ac-8d60-4158-9036-de79fa274983"
   },
   "source": [
    "With the job completed, we'll retrieve the results and review the responses generated for each request. The results are parsed. To fetch the results from the platform, you need to retrieve the `output_file_id` from the batch job, and then use the `files.content` endpoint, providing that specific file ID. Note that the job status must be `completed` for you to retrieve the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "806a5eb1-f6d3-491d-b051-9d44bf046a7e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "806a5eb1-f6d3-491d-b051-9d44bf046a7e",
    "outputId": "c236bf79-433f-4929-ce52-0708ecd43a30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracted Responses:\n",
      "Romance\n",
      "Drama\n",
      "Drama\n",
      "Drama\n",
      "Action\n"
     ]
    }
   ],
   "source": [
    "#Parse results as a JSON object\n",
    "def parse_json_objects(data_string):\n",
    "    if isinstance(data_string, bytes):\n",
    "        data_string = data_string.decode('utf-8')\n",
    "\n",
    "    json_strings = data_string.strip().split('\\n')\n",
    "    json_objects = []\n",
    "\n",
    "    for json_str in json_strings:\n",
    "        try:\n",
    "            json_obj = json.loads(json_str)\n",
    "            json_objects.append(json_obj)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error parsing JSON: {e}\")\n",
    "\n",
    "    return json_objects\n",
    "\n",
    "# Retrieve results with job ID\n",
    "job = client.batches.retrieve(batch_job.id)\n",
    "result_file_id = job.output_file_id\n",
    "result = client.files.content(result_file_id).content\n",
    "\n",
    "# Parse JSON results\n",
    "parsed_result = parse_json_objects(result)\n",
    "\n",
    "# Extract and print only the content of each response\n",
    "print(\"\\nExtracted Responses:\")\n",
    "for item in parsed_result:\n",
    "    try:\n",
    "        content = item[\"response\"][\"body\"][\"choices\"][0][\"message\"][\"content\"]\n",
    "        print(content)\n",
    "    except KeyError as e:\n",
    "        print(f\"Missing key in response: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e0e816-6558-4ff2-bab2-f85cff00bfc8",
   "metadata": {
    "id": "70e0e816-6558-4ff2-bab2-f85cff00bfc8"
   },
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d195dd1-1293-4407-b6ad-cab7e77b14c0",
   "metadata": {
    "id": "7d195dd1-1293-4407-b6ad-cab7e77b14c0"
   },
   "source": [
    "This tutorial used the chat completion endpoint to perform a simple text classification task with batch inference. This particular example clasified a series of movies based on their description.\n",
    "\n",
    "To submit a batch job we've:\n",
    "\n",
    "1. Created the JSONL file, where each line of the file represented a separate request\n",
    "2. Submitted the file to the platform\n",
    "3. Started the batch job, and monitored its progress\n",
    "4. Once completed, we fetched the results\n",
    "\n",
    "All of this using the OpenAI Python library and API, no changes needed!\n",
    "\n",
    "Kluster.ai's batch API empowers you to scale your workflows seamlessly, making it an invaluable tool for processing extensive datasets. As next steps, feel free to create your own dataset, or expand on top of this existing example. Good luck!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
