{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be189fde-4e5b-4f80-bae1-ded86a5075a7",
   "metadata": {
    "id": "be189fde-4e5b-4f80-bae1-ded86a5075a7"
   },
   "source": [
    "# Multiple inference requests with kluster.ai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17a77d9",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/kluster-ai/klusterai-cookbook/blob/main/examples/multiple-tasks-batch-api.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1d06ea-79c1-4f28-b312-0e5aabe18ff3",
   "metadata": {
    "id": "6d1d06ea-79c1-4f28-b312-0e5aabe18ff3"
   },
   "source": [
    "In other notebooks, we used AI models to perform simple tasks like <a href=\"/tutorials/klusterai-api/text-classification/text-classification-openai-api/\" target=\"_blank\">text classification</a>, <a href=\"/tutorials/klusterai-api/sentiment-analysis-api/\" target=\"_blank\">sentiment analysis</a> and <a href=\"/tutorials/klusterai-api/keyword-extraction-api/\" target=\"_blank\">keyword extraction</a>.\n",
    "\n",
    "This tutorial runs through a notebook where you'll learn how to use the <a href=\"https://kluster.ai/\" target=\"_blank\">kluster.ai</a> batch API to combine different tasks into a single batch file. Note that each task in the JSONL file can have its own model, system prompt, and particular request.\n",
    "\n",
    "You can adapt this example by using your data and categories relevant to your use case. With this approach, you can effortlessly process datasets of any scale, big or small, and obtain categorized results powered by a state-of-the-art language model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861366d9",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6c9189",
   "metadata": {},
   "source": [
    "Before getting started, ensure you have the following:\n",
    "\n",
    "- **A kluster.ai account** - sign up on the <a href=\"https://platform.kluster.ai/signup\" target=\"_blank\">kluster.ai platform</a> if you don't have one\n",
    "- **A kluster.ai API key** - after signing in, go to the <a href=\"https://platform.kluster.ai/apikeys\" target=\"_blank\">**API Keys**</a> section and create a new key. For detailed instructions, check out the <a href=\"/get-started/get-api-key/\" target=\"_blank\">Get an API key</a> guide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xU1WBQJ7Uh09",
   "metadata": {
    "id": "xU1WBQJ7Uh09"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd97579",
   "metadata": {},
   "source": [
    "In this notebook, we'll use Python's `getpass` module to safely input the key. After execution, please provide your unique kluster.ai API key (ensure no spaces)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4911e5eb-7463-4a6b-8a99-9313cecd9d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your kluster.ai API key:  ········\n"
     ]
    }
   ],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "api_key = getpass(\"Enter your kluster.ai API key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a0f1b2-947e-41ba-b4cc-dd313714247e",
   "metadata": {},
   "source": [
    "Next, ensure you've installed OpenAI Python library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcc3d475-8f49-4fc4-9a5e-c6eb6866d2b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3703623-786f-49cb-9aca-dc0a942155c8",
   "metadata": {},
   "source": [
    "With the OpenAI Python library installed, we import the necessary dependencies for the tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b89a4feb-37a9-430d-a742-cd58495b4eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "import urllib.request\n",
    "import requests\n",
    "from IPython.display import clear_output, display\n",
    "\n",
    "pd.set_option('display.max_columns', 1000, 'display.width', 1000, 'display.max_rows',1000, 'display.max_colwidth', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21b036b-6350-4bb9-9597-9a9edab95e53",
   "metadata": {},
   "source": [
    "And then, initialize the `client` by pointing it to the kluster.ai endpoint, and passing your API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "zG9y_WO5rYaj",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the client\n",
    "client = OpenAI(\n",
    "    base_url=\"https://api.kluster.ai/v1\",\n",
    "    api_key=api_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "udPtLfTaisSw",
   "metadata": {
    "id": "udPtLfTaisSw"
   },
   "source": [
    "## Get the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QjCVfg65jKz6",
   "metadata": {
    "id": "QjCVfg65jKz6"
   },
   "source": [
    "Now that you've initialized an OpenAI-compatible client pointing to kluster.ai, we can discuss the data.\n",
    "\n",
    "This notebook includes three sample datasets: Amazon musical instruments reviews, Top 1000 IMDb Movies, and AG News sample.\n",
    "\n",
    "The following code fetches the data and the last 5 data points of a single data sample. Feel free to change this or bring your own dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "yC9wJlV4rwOh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets\n",
    "#1. Amazon musical instruments reviews sample dataset\n",
    "#url = \"https://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Musical_Instruments_5.json.gz\"\n",
    "#2. IMDB top 1000 sample dataset\n",
    "#url = \"https://raw.githubusercontent.com/kluster-ai/klusterai-cookbook/refs/heads/main/data/imdb_top_1000.csv\" \n",
    "#3. AG News sample dataset\n",
    "url = \"https://raw.githubusercontent.com/kluster-ai/klusterai-cookbook/refs/heads/main/data/ag_news.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07018f92-9a01-47d5-916a-12cd03dfa3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset downloaded and saved as data/ag_news.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Feds Accused of Exaggerating Fire Impact (AP): AP - The Forest Service exaggerated the effect of wildfires on California spotted owls in justifying a planned increase in logging in the Sierra Nevada, according to a longtime agency expert who worked on the plan.: nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New Method May Predict Quakes Weeks Ahead (AP): AP - Swedish geologists may have found a way to predict earthquakes weeks before they happen by monitoring the amount of metals like zinc and copper in subsoil water near earthquake sites, scientists said Wednesday.: nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Marine Expedition Finds New Species (AP): AP - Norwegian scientists who explored the deep waters of the Atlantic Ocean said Thursday their findings  #151; including what appear to be new species of fish and squid  #151; could be used to protect marine ecosystems worldwide.: nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                     text\n",
       "0              Feds Accused of Exaggerating Fire Impact (AP): AP - The Forest Service exaggerated the effect of wildfires on California spotted owls in justifying a planned increase in logging in the Sierra Nevada, according to a longtime agency expert who worked on the plan.: nan\n",
       "1            New Method May Predict Quakes Weeks Ahead (AP): AP - Swedish geologists may have found a way to predict earthquakes weeks before they happen by monitoring the amount of metals like zinc and copper in subsoil water near earthquake sites, scientists said Wednesday.: nan\n",
       "2  Marine Expedition Finds New Species (AP): AP - Norwegian scientists who explored the deep waters of the Atlantic Ocean said Thursday their findings  #151; including what appear to be new species of fish and squid  #151; could be used to protect marine ecosystems worldwide.: nan"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fetch_dataset(url, file_path=None):\n",
    "  \n",
    "  # Set the default file path based on the URL if none is provided\n",
    "  if not file_path:\n",
    "    file_path = os.path.join(\"data\", os.path.basename(url))\n",
    "\n",
    "  # Create the directory if it does not exist\n",
    "  os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "\n",
    "  # Download the file if it doesn't already exist\n",
    "  if not os.path.exists(file_path):\n",
    "    urllib.request.urlretrieve(url, file_path)\n",
    "    print(f\"Dataset downloaded and saved as {file_path}\")\n",
    "  else:\n",
    "    print(f\"Using cached file at {file_path}\")\n",
    "\n",
    "  # Load and process the dataset based on URL content\n",
    "  if \"imdb_top_1000.csv\" in url:\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['text'] = df['Series_Title'].astype(str) + \": \" + df['Overview'].astype(str)\n",
    "    df = df[['text']]\n",
    "  elif \"ag_news\" in url:\n",
    "    df = pd.read_csv(file_path, header=None, names=[\"label\", \"title\", \"description\"])\n",
    "    df['text'] = df['title'].astype(str) + \": \" + df['description'].astype(str)\n",
    "    df = df[['text']]\n",
    "  elif \"reviews_Musical_Instruments_5.json.gz\" in url:\n",
    "    df = pd.read_json(file_path, compression='gzip', lines=True)\n",
    "    df.rename(columns={'reviewText': 'text'}, inplace=True)\n",
    "    df = df[['text']]\n",
    "  else:\n",
    "    raise ValueError(\"URL does not match any known dataset format.\")\n",
    "\n",
    "  return df[['text']].tail(3).reset_index(drop=True) # Return last 3 entries resetting the index\n",
    "\n",
    "# Fetch dataset\n",
    "df = fetch_dataset(url=url, file_path=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ehGwA0XRA87y",
   "metadata": {
    "id": "ehGwA0XRA87y"
   },
   "source": [
    "Now that we've fetched and saved the dataset let's move to the batch inference flow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "w-Lux3oUjfYI",
   "metadata": {
    "id": "w-Lux3oUjfYI"
   },
   "source": [
    "## Define the requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zjm-ST7dkHKm",
   "metadata": {
    "id": "zjm-ST7dkHKm"
   },
   "source": [
    "For this particular tutorial, we predefined five requests for the model to execute based on common customer use cases:\n",
    "\n",
    "- **Sentiment analysis** - reviewing text to determine whether there is positive, neutral, or negative notation to the statement\n",
    "- **Translation** - translate the text to any other language, in this example, Spanish\n",
    "- **Summarization** - express the text in a concise form\n",
    "- **Topic classification** - classify the text between a given set of categories\n",
    "- **Keyword extraction** - provide a number of keywords\n",
    "\n",
    "Requests are defined as a system prompt. This example runs through different types of requests, so they are defined as JSON objects. For each use case, we also defined the structure of the response we expect from the model.\n",
    "\n",
    "If you’re happy with these requests and structure, you can simply run the code as-is. However, if you’d like to customize them, please modify the prompts (or add new ones) to make personal requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8838ccb-c29b-477d-b15f-a95741aa528f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPTS = {\n",
    "  'sentiment': '''\n",
    "  Analyze the sentiment of the given text. Provide only a JSON object with the following structure:\n",
    "  {\n",
    "    \"sentiment\": string, // \"positive\", \"negative\", or \"neutral\"\n",
    "    \"confidence\": float, // A value between 0 and 1 indicating your confidence in the sentiment analysis\n",
    "  }\n",
    "  ''',\n",
    "\n",
    "  'translation': '''\n",
    "  Translate the given text from English to Spanish, paraphrase, rewrite or perform cultural adaptations for the text to make sense in Spanish. Provide only a JSON object with the following structure:\n",
    "  {\n",
    "    \"translation\": string, // The Spanish translation\n",
    "    \"notes\": string // Any notes about the translation, such as cultural adaptations or challenging phrases (max 500 words). Write this mainly in English.\n",
    "  }\n",
    "  ''',\n",
    "\n",
    "  'summary': '''\n",
    "  Summarize the main points of the given text. Provide only a JSON object with the following structure:\n",
    "  {\n",
    "    \"summary\": string, // A concise summary of the text (max 100 words)\n",
    "  }\n",
    "  ''',\n",
    "\n",
    "  'topic_classification': '''\n",
    "  Classify the main topic of the given text based on the following categories: \"politics\", \"sports\", \"technology\", \"science\", \"business\", \"entertainment\", \"health\", \"other\". Provide only a JSON object with the following structure:\n",
    "  {\n",
    "    \"category\": string, // The primary category of the provided text\n",
    "    \"confidence\": float, // A value between 0 and 1 indicating confidence in the classification\n",
    "  }\n",
    "  ''',\n",
    "\n",
    "  'keyword_extraction': '''\n",
    "  Extract relevant keywords from the given text. Provide only a JSON object with the following structure:\n",
    "  {\n",
    "    \"keywords\": string[], // An array of up to 5 keywords that best represent the text content\n",
    "    \"context\": string // Briefly explain how each keyword is relevant to the text (max 200 words)\n",
    "  }\n",
    "  '''\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Ew-R24Ltp5EW",
   "metadata": {
    "id": "Ew-R24Ltp5EW"
   },
   "source": [
    "### Create the batch job file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qS4JXT52wGJ-",
   "metadata": {
    "id": "qS4JXT52wGJ-"
   },
   "source": [
    "This example selects the `deepseek-ai/DeepSeek-V3` model. If you'd like to use a different model, feel free to change it by modifying the `model` field. In this notebook, you can also comment DeepSeek V3, and uncomment whatever model you want to try out.\n",
    "\n",
    "Please refer to the <a href=\"/get-started/start-building/batch/#supported-models\" target=\"_blank\">Supported models</a> section for a list of the models we support.\n",
    "\n",
    "The following snippets prepare the JSONL file, where each line represents a different request. Note that each separate batch request can have its own model. Also, we are using a temperature of `0.5` but feel free to change it and play around with the different outcomes (but we are only asking to respond with a single word, the genre)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fVtwyqZ_nEq7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "#model=\"deepseek-ai/DeepSeek-R1\"\n",
    "model=\"deepseek-ai/DeepSeek-V3\"\n",
    "#model=\"klusterai/Meta-Llama-3.1-8B-Instruct-Turbo\"\n",
    "#model=\"klusterai/Meta-Llama-3.1-405B-Instruct-Turbo\"\n",
    "#model=\"klusterai/Meta-Llama-3.3-70B-Instruct-Turbo\"\n",
    "#model=\"Qwen/Qwen2.5-VL-7B-Instruct\"\n",
    "\n",
    "def create_batch_file(df, inference_type, system_prompt):\n",
    "  batch_list = []\n",
    "  for index, row in df.iterrows():\n",
    "    content = row[\"text\"]\n",
    "\n",
    "    request = {\n",
    "      \"custom_id\": f\"{inference_type}-{index}\",\n",
    "      \"method\": \"POST\",\n",
    "      \"url\": \"/v1/chat/completions\",\n",
    "      \"body\": {\n",
    "        \"model\": model,\n",
    "        \"temperature\": 0.5,\n",
    "        \"messages\": [\n",
    "          {\"role\": \"system\", \"content\": system_prompt},\n",
    "          {\"role\": \"user\", \"content\": content},\n",
    "        ],\n",
    "      },\n",
    "    }\n",
    "    batch_list.append(request)\n",
    "  return batch_list\n",
    "\n",
    "\n",
    "def save_batch_file(batch_list, inference_type):\n",
    "  filename = f\"data/batch_request_{inference_type}.jsonl\"\n",
    "  with open(filename, \"w\") as file:\n",
    "    for request in batch_list:\n",
    "      file.write(json.dumps(request) + \"\\n\")\n",
    "  return filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "qNhmrmHdnp7g",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File data/batch_request_sentiment.jsonl saved\n",
      "File data/batch_request_translation.jsonl saved\n",
      "File data/batch_request_summary.jsonl saved\n",
      "File data/batch_request_topic_classification.jsonl saved\n",
      "File data/batch_request_keyword_extraction.jsonl saved\n"
     ]
    }
   ],
   "source": [
    "batch_requests = []\n",
    "\n",
    "# Loop through all the different prompts\n",
    "for inference_type, system_prompt in SYSTEM_PROMPTS.items():\n",
    "  batch_list = create_batch_file(df, inference_type, system_prompt)\n",
    "  filename = save_batch_file(batch_list, inference_type)\n",
    "  batch_requests.append((inference_type, filename))\n",
    "  print(f\"File {filename} saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f4fa90-5d9c-448e-9a6d-8a9cf77bda6c",
   "metadata": {},
   "source": [
    "Next, we can preview what a single batch job looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dacb59ff-9dbf-4f71-a2eb-29ccaa05e516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"custom_id\": \"sentiment-0\", \"method\": \"POST\", \"url\": \"/v1/chat/completions\", \"body\": {\"model\": \"deepseek-ai/DeepSeek-V3\", \"temperature\": 0.5, \"messages\": [{\"role\": \"system\", \"content\": \"\\n  Analyze the sentiment of the given text. Provide only a JSON object with the following structure:\\n  {\\n    \\\"sentiment\\\": string, // \\\"positive\\\", \\\"negative\\\", or \\\"neutral\\\"\\n    \\\"confidence\\\": float, // A value between 0 and 1 indicating your confidence in the sentiment analysis\\n  }\\n  \"}, {\"role\": \"user\", \"content\": \"Feds Accused of Exaggerating Fire Impact (AP): AP - The Forest Service exaggerated the effect of wildfires on California spotted owls in justifying a planned increase in logging in the Sierra Nevada, according to a longtime agency expert who worked on the plan.: nan\"}]}}\n",
      "{\"custom_id\": \"sentiment-1\", \"method\": \"POST\", \"url\": \"/v1/chat/completions\", \"body\": {\"model\": \"deepseek-ai/DeepSeek-V3\", \"temperature\": 0.5, \"messages\": [{\"role\": \"system\", \"content\": \"\\n  Analyze the sentiment of the given text. Provide only a JSON object with the following structure:\\n  {\\n    \\\"sentiment\\\": string, // \\\"positive\\\", \\\"negative\\\", or \\\"neutral\\\"\\n    \\\"confidence\\\": float, // A value between 0 and 1 indicating your confidence in the sentiment analysis\\n  }\\n  \"}, {\"role\": \"user\", \"content\": \"New Method May Predict Quakes Weeks Ahead (AP): AP - Swedish geologists may have found a way to predict earthquakes weeks before they happen by monitoring the amount of metals like zinc and copper in subsoil water near earthquake sites, scientists said Wednesday.: nan\"}]}}\n",
      "{\"custom_id\": \"sentiment-2\", \"method\": \"POST\", \"url\": \"/v1/chat/completions\", \"body\": {\"model\": \"deepseek-ai/DeepSeek-V3\", \"temperature\": 0.5, \"messages\": [{\"role\": \"system\", \"content\": \"\\n  Analyze the sentiment of the given text. Provide only a JSON object with the following structure:\\n  {\\n    \\\"sentiment\\\": string, // \\\"positive\\\", \\\"negative\\\", or \\\"neutral\\\"\\n    \\\"confidence\\\": float, // A value between 0 and 1 indicating your confidence in the sentiment analysis\\n  }\\n  \"}, {\"role\": \"user\", \"content\": \"Marine Expedition Finds New Species (AP): AP - Norwegian scientists who explored the deep waters of the Atlantic Ocean said Thursday their findings  #151; including what appear to be new species of fish and squid  #151; could be used to protect marine ecosystems worldwide.: nan\"}]}}\n"
     ]
    }
   ],
   "source": [
    "!head -n 5 data/batch_request_sentiment.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xArKu7-sqSiR",
   "metadata": {
    "id": "xArKu7-sqSiR"
   },
   "source": [
    "### Upload batch job files to kluster.ai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3ed12b",
   "metadata": {},
   "source": [
    "Now that we've prepared our input files, it's time to upload it to the kluster.ai platform. To do so, you can use the `files.create` endpoint of the client, where the purpose is set to `batch`. This will return the file ID, which we need to log for the next steps. We will repeat the process for each batch file created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "l5eu5UyAnEtk",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_batch_file(data_dir):\n",
    "  print(f\"Creating request for {data_dir}\")\n",
    "  \n",
    "  with open(data_dir, 'rb') as file:\n",
    "    upload_response = client.files.create(\n",
    "    file=file,\n",
    "    purpose=\"batch\"\n",
    "  )\n",
    "\n",
    "  # Print job ID\n",
    "  file_id = upload_response.id\n",
    "  print(f\"File uploaded successfully. File ID: {file_id}\")\n",
    "\n",
    "  return upload_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "jwzlrHCTp2LO",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading file data/batch_request_topic_classification.jsonl\n",
      "Creating request for data/batch_request_topic_classification.jsonl\n",
      "File uploaded successfully. File ID: 67e40792a135957969fda091\n",
      "Uploading file data/batch_request_keyword_extraction.jsonl\n",
      "Creating request for data/batch_request_keyword_extraction.jsonl\n",
      "File uploaded successfully. File ID: 67e40792c72788860894306f\n",
      "Uploading file data/batch_request_translation.jsonl\n",
      "Creating request for data/batch_request_translation.jsonl\n",
      "File uploaded successfully. File ID: 67e40793a135957969fda097\n",
      "Uploading file data/batch_request_sentiment.jsonl\n",
      "Creating request for data/batch_request_sentiment.jsonl\n",
      "File uploaded successfully. File ID: 67e407930fdb60564c2bb237\n",
      "Uploading file data/batch_request_summary.jsonl\n",
      "Creating request for data/batch_request_summary.jsonl\n",
      "File uploaded successfully. File ID: 67e40794ce6b9bab9cadaf34\n"
     ]
    }
   ],
   "source": [
    "batch_files = []\n",
    "DATA_FOLDER = \"data\"\n",
    "\n",
    "# Loop through all .jsonl files in the data folder\n",
    "for file in os.listdir(DATA_FOLDER):\n",
    "  if file.endswith(\".jsonl\"):\n",
    "    data_dir = os.path.join(DATA_FOLDER, file)\n",
    "    print(f\"Uploading file {data_dir}\")\n",
    "    job = upload_batch_file(data_dir)\n",
    "    batch_files.append((data_dir, job))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca918c23",
   "metadata": {},
   "source": [
    "All files are now uploaded, and we can proceed with creating the batch jobs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28957bce-13e9-4d3a-9599-4809c37c5723",
   "metadata": {},
   "source": [
    "### Start the batch job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c708a4-8766-4201-bcd3-de8d26f2f361",
   "metadata": {},
   "source": [
    "Once all the files have been successfully uploaded, we're ready to start (create) the batch jobs by providing the file ID of each file, which we got in the previous step. To start each job, we use the `batches.create` method, for which we need to set the endpoint to `/v1/chat/completions`. This will return each batch job details, with each ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07f43785-c5e5-4953-8b81-1bef003e060f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create batch job with completions endpoint\n",
    "def create_batch_job(file_id):\n",
    "  batch_job = client.batches.create(\n",
    "    input_file_id=file_id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\"\n",
    "  )\n",
    "\n",
    "  print(f\"Batch job created with ID {batch_job.id}\")\n",
    "  return batch_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d4806fb-6984-4d41-8fd9-f405cdb432e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating batch job for file ID 67e40792a135957969fda091\n",
      "Batch job created with ID 67e40798ce6b9bab9cadaf56\n",
      "Creating batch job for file ID 67e40792c72788860894306f\n",
      "Batch job created with ID 67e407a2a135957969fda1b4\n",
      "Creating batch job for file ID 67e40793a135957969fda097\n",
      "Batch job created with ID 67e407adc7278886089431ea\n",
      "Creating batch job for file ID 67e407930fdb60564c2bb237\n",
      "Batch job created with ID 67e407b7c727888608943275\n",
      "Creating batch job for file ID 67e40794ce6b9bab9cadaf34\n",
      "Batch job created with ID 67e407c2a135957969fda38e\n"
     ]
    }
   ],
   "source": [
    "batch_jobs = []\n",
    "\n",
    "for dir_path, batch_file in batch_files:\n",
    "    print(f\"Creating batch job for file ID {batch_file.id}\")\n",
    "    batch_job = create_batch_job(batch_file.id)\n",
    "    batch_jobs.append(batch_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e-ujphILqepu",
   "metadata": {
    "id": "e-ujphILqepu"
   },
   "source": [
    "### Check job progress"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iFrDrriQqizC",
   "metadata": {
    "id": "iFrDrriQqizC"
   },
   "source": [
    "Now that your batch jobs have been created, you can track their progress.\n",
    "\n",
    "To monitor the job's progress, we can use the `batches.retrieve` method and pass the batch job ID. The response contains a `status` field that tells us if it is completed or not and the subsequent status of each job separately. We can repeat this process for every batch job ID we got in the previous step.\n",
    "\n",
    "The following snippet checks the status of all batch jobs every 10 seconds until the entire batch is completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "SuH0CfoqjP3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def monitor_batch_jobs(batch_jobs):\n",
    "  all_completed = False\n",
    "\n",
    "  while not all_completed:\n",
    "    all_completed = True\n",
    "    output_lines = []\n",
    "\n",
    "    for job in batch_jobs:\n",
    "      updated_job = client.batches.retrieve(job.id)\n",
    "\n",
    "      if updated_job.status != \"completed\":\n",
    "        all_completed = False\n",
    "        completed = updated_job.request_counts.completed\n",
    "        total = updated_job.request_counts.total\n",
    "        output_lines.append(f\"Job {job.id} status: {updated_job.status} - Progress: {completed}/{total}\")\n",
    "      else:\n",
    "        output_lines.append(f\"Job {job.id} completed!\")\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    for line in output_lines:\n",
    "      display(line)\n",
    "\n",
    "    if not all_completed:\n",
    "      time.sleep(refresh_interval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a283b51-1585-4f64-89fb-784952e65fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Job 67e40798ce6b9bab9cadaf56 completed!'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Job 67e407a2a135957969fda1b4 completed!'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Job 67e407adc7278886089431ea completed!'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Job 67e407b7c727888608943275 completed!'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Job 67e407c2a135957969fda38e completed!'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "monitor_batch_jobs(batch_jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TkkhIG9HU0D9",
   "metadata": {
    "id": "TkkhIG9HU0D9"
   },
   "source": [
    "## Get the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d9215f",
   "metadata": {},
   "source": [
    "With all jobs completed, we'll retrieve the results and review the responses generated for each request. The results are parsed. To fetch the results from the platform, you need to retrieve the `output_file_id` from the batch job, and then use the `files.content` endpoint, providing that specific file ID. We will repeat this for every single batch job id. Note that the job status must be `completed` for you to retrieve the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "caA5djbLrJ4O",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parse results as a JSON object\n",
    "def parse_json_objects(data_string):\n",
    "  if isinstance(data_string, bytes):\n",
    "    data_string = data_string.decode('utf-8')\n",
    "\n",
    "  json_strings = data_string.strip().split('\\n')\n",
    "  json_objects = []\n",
    "\n",
    "  for json_str in json_strings:\n",
    "    try:\n",
    "      json_obj = json.loads(json_str)\n",
    "      json_objects.append(json_obj)\n",
    "    except json.JSONDecodeError as e:\n",
    "      print(f\"Error parsing JSON: {e}\")\n",
    "\n",
    "  return json_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f86d9b6e-06f6-4a18-a56a-913ab58fc7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------------- \n",
      "\n",
      "Inference ID: topic_classification-0. \n",
      "\n",
      "TEXT: Feds Accused of Exaggerating Fire Impact (AP): AP - The Forest Service exaggerated the effect of wildfires on California spotted owls in justifying a planned increase in logging in the Sierra Nevada, according to a longtime agency expert who worked on the plan.: nan\n",
      "\n",
      "RESULT: ```json\n",
      "{\n",
      "  \"category\": \"politics\",\n",
      "  \"confidence\": 0.7\n",
      "}\n",
      "```\n",
      "\n",
      " -------------------------- \n",
      "\n",
      "Inference ID: topic_classification-1. \n",
      "\n",
      "TEXT: New Method May Predict Quakes Weeks Ahead (AP): AP - Swedish geologists may have found a way to predict earthquakes weeks before they happen by monitoring the amount of metals like zinc and copper in subsoil water near earthquake sites, scientists said Wednesday.: nan\n",
      "\n",
      "RESULT: {\n",
      "    \"category\": \"science\",\n",
      "    \"confidence\": 0.95\n",
      "}\n",
      "\n",
      " -------------------------- \n",
      "\n",
      "Inference ID: topic_classification-2. \n",
      "\n",
      "TEXT: Marine Expedition Finds New Species (AP): AP - Norwegian scientists who explored the deep waters of the Atlantic Ocean said Thursday their findings  #151; including what appear to be new species of fish and squid  #151; could be used to protect marine ecosystems worldwide.: nan\n",
      "\n",
      "RESULT: ```json\n",
      "{\n",
      "  \"category\": \"science\",\n",
      "  \"confidence\": 0.95\n",
      "}\n",
      "```\n",
      "\n",
      " -------------------------- \n",
      "\n",
      "Inference ID: keyword_extraction-0. \n",
      "\n",
      "TEXT: Feds Accused of Exaggerating Fire Impact (AP): AP - The Forest Service exaggerated the effect of wildfires on California spotted owls in justifying a planned increase in logging in the Sierra Nevada, according to a longtime agency expert who worked on the plan.: nan\n",
      "\n",
      "RESULT: ```json\n",
      "{\n",
      "  \"keywords\": [\"Forest Service\", \"wildfires\", \"California spotted owls\", \"logging\", \"Sierra Nevada\"],\n",
      "  \"context\": \"The Forest Service is accused of overstating the impact of wildfires on California spotted owls to justify increased logging in the Sierra Nevada. 'Forest Service' is central as it is the agency involved. 'Wildfires' are the environmental event being discussed. 'California spotted owls' are the species allegedly affected. 'Logging' is the planned activity being justified. 'Sierra Nevada' is the geographic location where these events are taking place.\"\n",
      "}\n",
      "```\n",
      "\n",
      " -------------------------- \n",
      "\n",
      "Inference ID: keyword_extraction-1. \n",
      "\n",
      "TEXT: New Method May Predict Quakes Weeks Ahead (AP): AP - Swedish geologists may have found a way to predict earthquakes weeks before they happen by monitoring the amount of metals like zinc and copper in subsoil water near earthquake sites, scientists said Wednesday.: nan\n",
      "\n",
      "RESULT: {\n",
      "  \"keywords\": [\"earthquake prediction\", \"geologists\", \"zinc\", \"copper\", \"subsoil water\"],\n",
      "  \"context\": \"The text discusses a new method for earthquake prediction developed by Swedish geologists. 'Earthquake prediction' is the central focus, as the method aims to forecast quakes weeks in advance. 'Geologists' are the scientists involved in this research. 'Zinc' and 'copper' are metals monitored in subsoil water near earthquake sites, which are key indicators in this predictive method. 'Subsoil water' is the medium where these metals are measured, making it a critical component of the study.\"\n",
      "}\n",
      "\n",
      " -------------------------- \n",
      "\n",
      "Inference ID: keyword_extraction-2. \n",
      "\n",
      "TEXT: Marine Expedition Finds New Species (AP): AP - Norwegian scientists who explored the deep waters of the Atlantic Ocean said Thursday their findings  #151; including what appear to be new species of fish and squid  #151; could be used to protect marine ecosystems worldwide.: nan\n",
      "\n",
      "RESULT: ```json\n",
      "{\n",
      "  \"keywords\": [\"Marine Expedition\", \"New Species\", \"Atlantic Ocean\", \"Norwegian Scientists\", \"Marine Ecosystems\"],\n",
      "  \"context\": \"The keywords highlight the core aspects of the text. 'Marine Expedition' refers to the scientific exploration conducted in the deep waters. 'New Species' emphasizes the discovery of previously unknown fish and squid. 'Atlantic Ocean' specifies the location of the expedition. 'Norwegian Scientists' identifies the researchers involved in the study. 'Marine Ecosystems' underscores the broader goal of using these findings to protect oceanic environments globally.\"\n",
      "}\n",
      "```\n",
      "\n",
      " -------------------------- \n",
      "\n",
      "Inference ID: translation-0. \n",
      "\n",
      "TEXT: Feds Accused of Exaggerating Fire Impact (AP): AP - The Forest Service exaggerated the effect of wildfires on California spotted owls in justifying a planned increase in logging in the Sierra Nevada, according to a longtime agency expert who worked on the plan.: nan\n",
      "\n",
      "RESULT: {\n",
      "  \"translation\": \"Acusan a las autoridades federales de exagerar el impacto de los incendios (AP): AP - El Servicio Forestal exageró el efecto de los incendios forestales en los búhos manchados de California para justificar un aumento planificado en la tala de árboles en Sierra Nevada, según un experto de larga trayectoria en la agencia que trabajó en el plan.\",\n",
      "  \"notes\": \"The translation maintains the original structure and meaning of the text. The term 'Feds' was translated as 'autoridades federales' to convey the informal tone in a way that is natural in Spanish. 'California spotted owls' was translated directly as 'búhos manchados de California' since it is a specific species name. 'Logging' was translated as 'tala de árboles' to clearly convey the activity. No significant cultural adaptations were needed, as the topic is universally understood in Spanish-speaking contexts.\"\n",
      "}\n",
      "\n",
      " -------------------------- \n",
      "\n",
      "Inference ID: translation-1. \n",
      "\n",
      "TEXT: New Method May Predict Quakes Weeks Ahead (AP): AP - Swedish geologists may have found a way to predict earthquakes weeks before they happen by monitoring the amount of metals like zinc and copper in subsoil water near earthquake sites, scientists said Wednesday.: nan\n",
      "\n",
      "RESULT: {\n",
      "  \"translation\": \"Nuevo método podría predecir terremotos con semanas de anticipación (AP): AP - Geólogos suecos podrían haber encontrado una manera de predecir terremotos semanas antes de que ocurran, mediante el monitoreo de la cantidad de metales como zinc y cobre en el agua subterránea cerca de zonas sísmicas, dijeron científicos el miércoles.\",\n",
      "  \"notes\": \"The translation maintains the original meaning and structure of the text. The phrase 'New Method May Predict Quakes Weeks Ahead' was translated as 'Nuevo método podría predecir terremotos con semanas de anticipación' to ensure clarity and accuracy. The term 'subsoil water' was translated as 'agua subterránea,' which is the common term used in Spanish for water found beneath the ground. The mention of 'Swedish geologists' and 'scientists' was kept as 'geólogos suecos' and 'científicos' respectively, as these terms are directly translatable and widely understood in Spanish. The date 'Wednesday' was translated as 'miércoles,' which is the standard translation for the day of the week in Spanish.\"\n",
      "}\n",
      "\n",
      " -------------------------- \n",
      "\n",
      "Inference ID: translation-2. \n",
      "\n",
      "TEXT: Marine Expedition Finds New Species (AP): AP - Norwegian scientists who explored the deep waters of the Atlantic Ocean said Thursday their findings  #151; including what appear to be new species of fish and squid  #151; could be used to protect marine ecosystems worldwide.: nan\n",
      "\n",
      "RESULT: {\n",
      "  \"translation\": \"Expedición Marina Descubre Nuevas Especies (AP): AP - Científicos noruegos que exploraron las aguas profundas del Océano Atlántico anunciaron el jueves que sus hallazgos —incluyendo lo que parecen ser nuevas especies de peces y calamares— podrían ser utilizados para proteger los ecosistemas marinos a nivel mundial.\",\n",
      "  \"notes\": \"The translation maintains the original structure and intent of the text. The phrase 'could be used to protect marine ecosystems worldwide' was translated directly as 'podrían ser utilizados para proteger los ecosistemas marinos a nivel mundial,' which is both accurate and culturally appropriate. No significant cultural adaptations were necessary. The use of 'nivel mundial' (worldwide) is common in Spanish to convey global scope.\"\n",
      "}\n",
      "\n",
      " -------------------------- \n",
      "\n",
      "Inference ID: sentiment-0. \n",
      "\n",
      "TEXT: Feds Accused of Exaggerating Fire Impact (AP): AP - The Forest Service exaggerated the effect of wildfires on California spotted owls in justifying a planned increase in logging in the Sierra Nevada, according to a longtime agency expert who worked on the plan.: nan\n",
      "\n",
      "RESULT: ```json\n",
      "{\n",
      "  \"sentiment\": \"negative\",\n",
      "  \"confidence\": 0.75\n",
      "}\n",
      "```\n",
      "\n",
      " -------------------------- \n",
      "\n",
      "Inference ID: sentiment-1. \n",
      "\n",
      "TEXT: New Method May Predict Quakes Weeks Ahead (AP): AP - Swedish geologists may have found a way to predict earthquakes weeks before they happen by monitoring the amount of metals like zinc and copper in subsoil water near earthquake sites, scientists said Wednesday.: nan\n",
      "\n",
      "RESULT: ```json\n",
      "{\n",
      "  \"sentiment\": \"neutral\",\n",
      "  \"confidence\": 0.95\n",
      "}\n",
      "```\n",
      "\n",
      " -------------------------- \n",
      "\n",
      "Inference ID: sentiment-2. \n",
      "\n",
      "TEXT: Marine Expedition Finds New Species (AP): AP - Norwegian scientists who explored the deep waters of the Atlantic Ocean said Thursday their findings  #151; including what appear to be new species of fish and squid  #151; could be used to protect marine ecosystems worldwide.: nan\n",
      "\n",
      "RESULT: ```json\n",
      "{\n",
      "  \"sentiment\": \"positive\",\n",
      "  \"confidence\": 0.9\n",
      "}\n",
      "```\n",
      "\n",
      " -------------------------- \n",
      "\n",
      "Inference ID: summary-0. \n",
      "\n",
      "TEXT: Feds Accused of Exaggerating Fire Impact (AP): AP - The Forest Service exaggerated the effect of wildfires on California spotted owls in justifying a planned increase in logging in the Sierra Nevada, according to a longtime agency expert who worked on the plan.: nan\n",
      "\n",
      "RESULT: {\n",
      "  \"summary\": \"A Forest Service expert claims the agency overstated the impact of wildfires on California spotted owls to justify increased logging in the Sierra Nevada.\"\n",
      "}\n",
      "\n",
      " -------------------------- \n",
      "\n",
      "Inference ID: summary-1. \n",
      "\n",
      "TEXT: New Method May Predict Quakes Weeks Ahead (AP): AP - Swedish geologists may have found a way to predict earthquakes weeks before they happen by monitoring the amount of metals like zinc and copper in subsoil water near earthquake sites, scientists said Wednesday.: nan\n",
      "\n",
      "RESULT: {\n",
      "  \"summary\": \"Swedish geologists have developed a potential method to predict earthquakes weeks in advance by monitoring levels of metals like zinc and copper in subsoil water near earthquake sites.\"\n",
      "}\n",
      "\n",
      " -------------------------- \n",
      "\n",
      "Inference ID: summary-2. \n",
      "\n",
      "TEXT: Marine Expedition Finds New Species (AP): AP - Norwegian scientists who explored the deep waters of the Atlantic Ocean said Thursday their findings  #151; including what appear to be new species of fish and squid  #151; could be used to protect marine ecosystems worldwide.: nan\n",
      "\n",
      "RESULT: {\n",
      "  \"summary\": \"Norwegian scientists exploring the Atlantic Ocean's deep waters discovered potential new species of fish and squid, which could aid in global marine ecosystem protection.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "for batch_job in batch_jobs:\n",
    "  job_status = client.batches.retrieve(batch_job.id)\n",
    "  result_file_id = job_status.output_file_id\n",
    "  result = client.files.content(result_file_id).content\n",
    "  results = parse_json_objects(result)\n",
    "\n",
    "  for res in results:\n",
    "    inference_id = res['custom_id']\n",
    "    index = inference_id.split('-')[-1]\n",
    "    result = res['response']['body']['choices'][0]['message']['content']\n",
    "    text = df.iloc[int(index)]['text']\n",
    "    print(f'\\n -------------------------- \\n')\n",
    "    print(f\"Inference ID: {inference_id}. \\n\\nTEXT: {text}\\n\\nRESULT: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9573d9e",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42bcd40",
   "metadata": {},
   "source": [
    "This tutorial used the chat completion endpoint to perform many tasks via kluster.ai batch API. This particular example performed five different tasks for each element of the dataset: sentiment analysis, translation (to Spanish), summarization, topic classification and keyword extraction.\n",
    "\n",
    "To submit a batch job we've:\n",
    "\n",
    "1. Created the JSONL file, where each line of the file represented a separate request (for each task and element of dataset)\n",
    "2. Submitted the file to the platform\n",
    "3. Started the batch job, and monitored its progress\n",
    "4. Once completed, we fetched the results\n",
    "\n",
    "All of this using the OpenAI Python library and API, no changes needed!\n",
    "\n",
    "Kluster.ai's batch API empowers you to scale your workflows seamlessly, making it an invaluable tool for processing extensive datasets. As next steps, feel free to create your own dataset, or expand on top of this existing example. Good luck!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
